{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import deepmatcher as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sample_data/itunes-amazon/train.csv')\n",
    "validation = pd.read_csv('sample_data/itunes-amazon/validation.csv')\n",
    "test = pd.read_csv('sample_data/itunes-amazon/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_positives = train[train['label']==1]\n",
    "train_negatives = train[train['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_positives = validation[validation['label']==1]\n",
    "validation_negatives = validation[validation['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_distribution(df):\n",
    "    prices = {}\n",
    "    for idx,row in df.iterrows():\n",
    "        current_prices = row['left_Price']+ \" \"+ row['right_Price']\n",
    "        if current_prices in prices:\n",
    "            prices[current_prices] += 1\n",
    "        else:\n",
    "            prices[current_prices] = 1\n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$ 1.29 $ 1.29': 153,\n",
       " 'Album Only $ 1.29': 20,\n",
       " '$ 1.29 $ 0.99': 18,\n",
       " '$ 1.99 $ 1.29': 25,\n",
       " '$ 1.29 $ 0.69': 3,\n",
       " '$ 0.99 $ 0.99': 11,\n",
       " '$ 1.99 $ 0.99': 3,\n",
       " '$ 0.99 $ 1.29': 11,\n",
       " '$ 0.99 $ 0.89': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_negatives = get_price_distribution(train_negatives)\n",
    "price_negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$ 0.99 $ 0.99': 17,\n",
       " '$ 1.29 $ 1.29': 58,\n",
       " '$ 1.99 $ 1.29': 1,\n",
       " '$ 1.29 $ 0.89': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_positives = get_price_distribution(train_positives)\n",
    "price_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation changing prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (attr_summarizers): ModuleMap(\n",
       "    (Song_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Genre): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Price): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Time): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Released): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_summarizer): Hybrid(\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge(\n",
       "    )\n",
       "    (Artist_Name): Merge(\n",
       "    )\n",
       "    (Album_Name): Merge(\n",
       "    )\n",
       "    (Genre): Merge(\n",
       "    )\n",
       "    (Price): Merge(\n",
       "    )\n",
       "    (CopyRight): Merge(\n",
       "    )\n",
       "    (Time): Merge(\n",
       "    )\n",
       "    (Released): Merge(\n",
       "    )\n",
       "  )\n",
       "  (attr_comparator): Merge(\n",
       "  )\n",
       "  (attr_merge): Merge(\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax()\n",
       "  )\n",
       "  (embed): ModuleMap(\n",
       "    (left_Song_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Album_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Genre): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Price): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_CopyRight): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Time): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Released): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Song_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Album_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Genre): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Price): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_CopyRight): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Time): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Released): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.load_state('models/hybrid_model.pth')\n",
    "hybrid_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on standard test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = dm.data.process_unlabeled('sample_data/itunes-amazon/test_positives.csv',trained_model=hybrid_model,\n",
    "                                ignore_columns = ['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 2\n",
      "Finished Epoch 2 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "standard_pred = hybrid_model.run_prediction(test_pos,output_attributes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 18)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_pred_neg = standard_pred[standard_pred['match_score']<=0.5]\n",
    "standard_pred_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on altered test set (on price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_positives = pd.read_csv('sample_data/itunes-amazon/test_positives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alter_price' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4f290a10c175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_pos_altered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malter_price\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_positives\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Album Only'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'$ 1.29'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'alter_price' is not defined"
     ]
    }
   ],
   "source": [
    "test_pos_altered = alter_price(test_positives,'Album Only','$ 1.29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_price(df,left_pr,right_pr):\n",
    "    df['left_Price'] = left_pr\n",
    "    df['right_Price'] = right_pr\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_altered.to_csv('sample_data/itunes-amazon/exp6/test_positives_altered_price.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_altered_price = dm.data.process_unlabeled('sample_data/itunes-amazon/exp6/test_positives_altered_price.csv'\n",
    "                                                   ,trained_model=hybrid_model,ignore_columns=['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 2\n",
      "Finished Epoch 2 || Run Time:    0.1 | Load Time:    0.2 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "altered_pred = hybrid_model.run_prediction(test_pos_altered_price,output_attributes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altered_pred_neg = altered_pred[altered_pred['match_score'] <=0.5]\n",
    "altered_pred_neg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate closer vectors on classifier space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neg = pd.read_csv('sample_data/itunes-amazon/exp3/negative_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Album_Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Price</th>\n",
       "      <th>CopyRight</th>\n",
       "      <th>Time</th>\n",
       "      <th>Released</th>\n",
       "      <th>Pos_sample_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>206</td>\n",
       "      <td>422</td>\n",
       "      <td>83</td>\n",
       "      <td>422</td>\n",
       "      <td>281</td>\n",
       "      <td>297</td>\n",
       "      <td>472</td>\n",
       "      <td>199</td>\n",
       "      <td>502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>438</td>\n",
       "      <td>418</td>\n",
       "      <td>491</td>\n",
       "      <td>398</td>\n",
       "      <td>281</td>\n",
       "      <td>420</td>\n",
       "      <td>290</td>\n",
       "      <td>397</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>426</td>\n",
       "      <td>402</td>\n",
       "      <td>341</td>\n",
       "      <td>401</td>\n",
       "      <td>281</td>\n",
       "      <td>199</td>\n",
       "      <td>472</td>\n",
       "      <td>290</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>180</td>\n",
       "      <td>418</td>\n",
       "      <td>492</td>\n",
       "      <td>182</td>\n",
       "      <td>281</td>\n",
       "      <td>420</td>\n",
       "      <td>256</td>\n",
       "      <td>397</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>244</td>\n",
       "      <td>418</td>\n",
       "      <td>491</td>\n",
       "      <td>421</td>\n",
       "      <td>281</td>\n",
       "      <td>420</td>\n",
       "      <td>233</td>\n",
       "      <td>397</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Song_Name  Artist_Name  Album_Name  Genre  Price  CopyRight  Time  \\\n",
       "127        206          422          83    422    281        297   472   \n",
       "128        438          418         491    398    281        420   290   \n",
       "129        426          402         341    401    281        199   472   \n",
       "130        180          418         492    182    281        420   256   \n",
       "131        244          418         491    421    281        420   233   \n",
       "\n",
       "     Released  Pos_sample_ID  \n",
       "127       199            502  \n",
       "128       397            250  \n",
       "129       290            313  \n",
       "130       397            276  \n",
       "131       397            503  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closer_negatives = pd.read_csv('experiments-results/exp3/positives_closer_vectors_on_attribute.csv',sep=';')\n",
    "closer_negatives.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df =pd.merge(left=all_neg,right=closer_negatives,left_on='id',right_on='Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>left_Price</th>\n",
       "      <th>right_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>328</td>\n",
       "      <td>$ 1.99</td>\n",
       "      <td>$ 0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328</td>\n",
       "      <td>$ 1.99</td>\n",
       "      <td>$ 0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>328</td>\n",
       "      <td>$ 1.99</td>\n",
       "      <td>$ 0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>281</td>\n",
       "      <td>Album Only</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>281</td>\n",
       "      <td>Album Only</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>281</td>\n",
       "      <td>Album Only</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>281</td>\n",
       "      <td>Album Only</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>281</td>\n",
       "      <td>Album Only</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>281</td>\n",
       "      <td>Album Only</td>\n",
       "      <td>$ 1.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  left_Price right_Price\n",
       "0  243      $ 0.99      $ 1.29\n",
       "1  328      $ 1.99      $ 0.99\n",
       "2  328      $ 1.99      $ 0.99\n",
       "3  328      $ 1.99      $ 0.99\n",
       "4  281  Album Only      $ 1.29\n",
       "5  281  Album Only      $ 1.29\n",
       "6  281  Album Only      $ 1.29\n",
       "7  281  Album Only      $ 1.29\n",
       "8  281  Album Only      $ 1.29\n",
       "9  281  Album Only      $ 1.29"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_columns = join_df.loc[:, ['id','left_Price','right_Price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_columns.to_csv('experiments-results/exp6/closer_negatives_prices.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new training set with different price distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in train.iterrows():\n",
    "    if row['label']==1:\n",
    "        if idx % 2 ==0:\n",
    "            train.at[idx,'left_Price'] = '$ 0.99'\n",
    "            train.at[idx,'right_Price'] = '$ 0.99'\n",
    "        else:\n",
    "            train.at[idx,'left_Price'] = '$ 1.29'\n",
    "            train.at[idx,'right_Price'] = '$ 1.29'\n",
    "    else:\n",
    "        if idx % 2 == 0:\n",
    "            train.at[idx,'left_Price'] = 'Album Only'\n",
    "            train.at[idx,'right_Price'] = '$ 1.29'\n",
    "        else:\n",
    "            train.at[idx,'left_Price'] = '$ 1.29'\n",
    "            train.at[idx,'right_Price'] = '$ 1.29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,row in validation.iterrows():\n",
    "    if row['label']==1:\n",
    "        if idx % 2 ==0:\n",
    "            validation.at[idx,'left_Price'] = '$ 0.99'\n",
    "            validation.at[idx,'right_Price'] = '$ 0.99'\n",
    "        else:\n",
    "            validation.at[idx,'left_Price'] = '$ 1.29'\n",
    "            validation.at[idx,'right_Price'] = '$ 1.29'\n",
    "    else:\n",
    "        if idx % 2 == 0:\n",
    "            validation.at[idx,'left_Price'] = 'Album Only'\n",
    "            validation.at[idx,'right_Price'] = '$ 1.29'\n",
    "        else:\n",
    "            validation.at[idx,'left_Price'] = '$ 1.29'\n",
    "            validation.at[idx,'right_Price'] = '$ 1.29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('sample_data/itunes-amazon/exp6/train_newprices.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.to_csv('sample_data/itunes-amazon/exp6/validation_newprices.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:deepmatcher.data.dataset:Rebuilding data cache because: ['One or more data files have been modified.']\n"
     ]
    }
   ],
   "source": [
    "train,valid,test = dm.data.process('sample_data/itunes-amazon/exp6',train='train_newprices.csv',\n",
    "                                   validation='validation_newprices.csv',test='test.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 17757810\n",
      "===>  TRAIN Epoch 1\n",
      "Finished Epoch 1 || Run Time:    7.8 | Load Time:    1.2 || F1:  43.01 | Prec:  29.70 | Rec:  77.92 || Ex/s:  36.00\n",
      "\n",
      "===>  EVAL Epoch 1\n",
      "Finished Epoch 1 || Run Time:    1.0 | Load Time:    0.4 || F1:  52.17 | Prec:  35.29 | Rec: 100.00 || Ex/s:  78.33\n",
      "\n",
      "* Best F1: 52.17391304347826\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n",
      "Finished Epoch 2 || Run Time:    7.7 | Load Time:    1.2 || F1:  74.74 | Prec:  62.83 | Rec:  92.21 || Ex/s:  36.04\n",
      "\n",
      "===>  EVAL Epoch 2\n",
      "Finished Epoch 2 || Run Time:    1.1 | Load Time:    0.4 || F1:  77.19 | Prec:  66.67 | Rec:  91.67 || Ex/s:  73.15\n",
      "\n",
      "* Best F1: 77.19298245614036\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n",
      "Finished Epoch 3 || Run Time:    7.7 | Load Time:    1.2 || F1:  85.06 | Prec:  76.29 | Rec:  96.10 || Ex/s:  36.19\n",
      "\n",
      "===>  EVAL Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.9 | Load Time:    0.4 || F1:  77.97 | Prec:  65.71 | Rec:  95.83 || Ex/s:  85.89\n",
      "\n",
      "* Best F1: 77.96610169491525\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n",
      "Finished Epoch 4 || Run Time:    7.4 | Load Time:    1.2 || F1:  92.12 | Prec:  86.36 | Rec:  98.70 || Ex/s:  37.58\n",
      "\n",
      "===>  EVAL Epoch 4\n",
      "Finished Epoch 4 || Run Time:    1.0 | Load Time:    0.4 || F1:  93.88 | Prec:  92.00 | Rec:  95.83 || Ex/s:  76.78\n",
      "\n",
      "* Best F1: 93.87755102040816\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n",
      "Finished Epoch 5 || Run Time:    7.4 | Load Time:    1.2 || F1:  97.47 | Prec:  95.06 | Rec: 100.00 || Ex/s:  37.68\n",
      "\n",
      "===>  EVAL Epoch 5\n",
      "Finished Epoch 5 || Run Time:    0.9 | Load Time:    0.3 || F1:  95.83 | Prec:  95.83 | Rec:  95.83 || Ex/s:  88.40\n",
      "\n",
      "* Best F1: 95.83333333333333\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n",
      "Finished Epoch 6 || Run Time:    7.4 | Load Time:    1.2 || F1:  98.70 | Prec:  98.70 | Rec:  98.70 || Ex/s:  37.53\n",
      "\n",
      "===>  EVAL Epoch 6\n",
      "Finished Epoch 6 || Run Time:    0.9 | Load Time:    0.4 || F1:  88.46 | Prec:  82.14 | Rec:  95.83 || Ex/s:  85.31\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n",
      "Finished Epoch 7 || Run Time:    6.9 | Load Time:    1.1 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  40.52\n",
      "\n",
      "===>  EVAL Epoch 7\n",
      "Finished Epoch 7 || Run Time:    0.9 | Load Time:    0.3 || F1:  88.46 | Prec:  82.14 | Rec:  95.83 || Ex/s:  88.71\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n",
      "Finished Epoch 8 || Run Time:    7.0 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  39.50\n",
      "\n",
      "===>  EVAL Epoch 8\n",
      "Finished Epoch 8 || Run Time:    0.9 | Load Time:    0.4 || F1:  88.46 | Prec:  82.14 | Rec:  95.83 || Ex/s:  87.20\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n",
      "Finished Epoch 9 || Run Time:    7.2 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  38.26\n",
      "\n",
      "===>  EVAL Epoch 9\n",
      "Finished Epoch 9 || Run Time:    0.9 | Load Time:    0.4 || F1:  88.46 | Prec:  82.14 | Rec:  95.83 || Ex/s:  84.84\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n",
      "Finished Epoch 10 || Run Time:    7.8 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.79\n",
      "\n",
      "===>  EVAL Epoch 10\n",
      "Finished Epoch 10 || Run Time:    1.2 | Load Time:    0.5 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  63.34\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 11\n",
      "Finished Epoch 11 || Run Time:    7.9 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.40\n",
      "\n",
      "===>  EVAL Epoch 11\n",
      "Finished Epoch 11 || Run Time:    1.0 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  75.99\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 12\n",
      "Finished Epoch 12 || Run Time:    7.5 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  37.07\n",
      "\n",
      "===>  EVAL Epoch 12\n",
      "Finished Epoch 12 || Run Time:    1.0 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  76.40\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 13\n",
      "Finished Epoch 13 || Run Time:    7.6 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  36.72\n",
      "\n",
      "===>  EVAL Epoch 13\n",
      "Finished Epoch 13 || Run Time:    1.0 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  81.25\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 14\n",
      "Finished Epoch 14 || Run Time:    8.1 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  34.50\n",
      "\n",
      "===>  EVAL Epoch 14\n",
      "Finished Epoch 14 || Run Time:    1.1 | Load Time:    0.5 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  67.76\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 15\n",
      "Finished Epoch 15 || Run Time:    7.7 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  36.08\n",
      "\n",
      "===>  EVAL Epoch 15\n",
      "Finished Epoch 15 || Run Time:    0.8 | Load Time:    0.3 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  93.28\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 16\n",
      "Finished Epoch 16 || Run Time:    7.8 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.20\n",
      "\n",
      "===>  EVAL Epoch 16\n",
      "Finished Epoch 16 || Run Time:    0.8 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  91.05\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 17\n",
      "Finished Epoch 17 || Run Time:    8.3 | Load Time:    1.4 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  33.30\n",
      "\n",
      "===>  EVAL Epoch 17\n",
      "Finished Epoch 17 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  81.72\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 18\n",
      "Finished Epoch 18 || Run Time:    7.4 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  37.36\n",
      "\n",
      "===>  EVAL Epoch 18\n",
      "Finished Epoch 18 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  84.65\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 19\n",
      "Finished Epoch 19 || Run Time:    7.4 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  37.27\n",
      "\n",
      "===>  EVAL Epoch 19\n",
      "Finished Epoch 19 || Run Time:    1.0 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  79.76\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 20\n",
      "Finished Epoch 20 || Run Time:    7.9 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.23\n",
      "\n",
      "===>  EVAL Epoch 20\n",
      "Finished Epoch 20 || Run Time:    1.0 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  78.56\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 21\n",
      "Finished Epoch 21 || Run Time:    7.2 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  38.70\n",
      "\n",
      "===>  EVAL Epoch 21\n",
      "Finished Epoch 21 || Run Time:    1.1 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  69.50\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 22\n",
      "Finished Epoch 22 || Run Time:    7.0 | Load Time:    1.1 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  39.61\n",
      "\n",
      "===>  EVAL Epoch 22\n",
      "Finished Epoch 22 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  82.55\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 23\n",
      "Finished Epoch 23 || Run Time:    7.9 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.15\n",
      "\n",
      "===>  EVAL Epoch 23\n",
      "Finished Epoch 23 || Run Time:    1.2 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  68.46\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 24\n",
      "Finished Epoch 24 || Run Time:    7.7 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  36.22\n",
      "\n",
      "===>  EVAL Epoch 24\n",
      "Finished Epoch 24 || Run Time:    0.8 | Load Time:    0.3 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  92.42\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 25\n",
      "Finished Epoch 25 || Run Time:    8.0 | Load Time:    1.3 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  34.90\n",
      "\n",
      "===>  EVAL Epoch 25\n",
      "Finished Epoch 25 || Run Time:    1.2 | Load Time:    0.5 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  66.12\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 26\n",
      "Finished Epoch 26 || Run Time:    7.8 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.74\n",
      "\n",
      "===>  EVAL Epoch 26\n",
      "Finished Epoch 26 || Run Time:    1.0 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  77.94\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 27\n",
      "Finished Epoch 27 || Run Time:    7.8 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  35.70\n",
      "\n",
      "===>  EVAL Epoch 27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 27 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  84.62\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 28\n",
      "Finished Epoch 28 || Run Time:    7.4 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  37.49\n",
      "\n",
      "===>  EVAL Epoch 28\n",
      "Finished Epoch 28 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  81.81\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 29\n",
      "Finished Epoch 29 || Run Time:    7.4 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  37.61\n",
      "\n",
      "===>  EVAL Epoch 29\n",
      "Finished Epoch 29 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  88.04\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 30\n",
      "Finished Epoch 30 || Run Time:    7.0 | Load Time:    1.2 || F1: 100.00 | Prec: 100.00 | Rec: 100.00 || Ex/s:  39.25\n",
      "\n",
      "===>  EVAL Epoch 30\n",
      "Finished Epoch 30 || Run Time:    0.9 | Load Time:    0.4 || F1:  90.20 | Prec:  85.19 | Rec:  95.83 || Ex/s:  86.31\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95.83333333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.run_train(train,valid,best_save_path='models/hybrid_pricebias.pth',pos_neg_ratio=4,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  EVAL Epoch 5\n",
      "Finished Epoch 5 || Run Time:    0.6 | Load Time:    0.4 || F1:  75.76 | Prec:  71.43 | Rec:  80.65 || Ex/s: 102.66\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.75757575757575"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.run_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_altered_price = dm.data.process_unlabeled('sample_data/itunes-amazon/exp6/test_positives_altered_price.csv'\n",
    "                                                   ,trained_model=hybrid_model,ignore_columns=['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 5\n",
      "Finished Epoch 5 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_new_model = hybrid_model.run_prediction(test_pos_altered_price,output_attributes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 18)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_neg_new_model = pred_new_model[pred_new_model['match_score']<=0.5]\n",
    "pred_neg_new_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = dm.data.process_unlabeled('sample_data/itunes-amazon/test_positives.csv',\n",
    "                                    trained_model=hybrid_model,ignore_columns=['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 5\n",
      "Finished Epoch 5 || Run Time:    0.2 | Load Time:    0.2 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_standardtest_newmodel = hybrid_model.run_prediction(test_pos,output_attributes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 18)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_standardtest_newmodel_negative = pred_standardtest_newmodel[pred_standardtest_newmodel['match_score']<=0.5]\n",
    "pred_neg_new_model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to alter price in test set,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = pd.read_csv('sample_data/itunes-amazon/test_positives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "alter_price(test_pos,'$ 0.99','$ 0.99')\n",
    "test_pos.to_csv('sample_data/itunes-amazon/exp6/test_pos_099price.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 18)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_099price = dm.data.process_unlabeled('sample_data/itunes-amazon/exp6/test_pos_099price.csv'\n",
    "                                                   ,trained_model=hybrid_model,ignore_columns=['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 5\n",
      "Finished Epoch 5 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = hybrid_model.run_prediction(test_pos_099price,output_attributes=True)\n",
    "negative_preds = preds[preds['match_score']<=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 18)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
