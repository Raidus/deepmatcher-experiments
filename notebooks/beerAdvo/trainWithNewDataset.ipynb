{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import deepmatcher as dm\n",
    "from utilities_functions.intermediate_layer_extraction import return_layer_input\n",
    "from utilities_functions.ri_calculator import find_smallest_variation_to_change\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTraingPositives = pd.read_csv('newPositiveSamples.csv')\n",
    "defaultTrain = pd.read_csv('../../Structured/Beer/merged_train.csv')\n",
    "defaultTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extendedTrain = pd.concat([defaultTrain,newTraingPositives])\n",
    "extendedTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extendedTrain.to_csv('../../Structured/Beer/extended_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extendedTrain[extendedTrain['label']==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:deepmatcher.data.dataset:Rebuilding data cache because: ['One or more data files have been modified.']\n"
     ]
    }
   ],
   "source": [
    "train,valid,test = dm.data.process('../../Structured/Beer',train='extended_train.csv',validation='merged_valid.csv',\n",
    "                                  test='merged_test.csv',left_prefix='ltable_',right_prefix='rtable_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (attr_summarizers): ModuleMap(\n",
       "    (Beer_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Brew_Factory_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Style): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (ABV): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_summarizer): Hybrid(\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Beer_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=75, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Brew_Factory_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=75, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Style): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=75, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ABV): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=75, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=75, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Beer_Name): Merge(\n",
       "    )\n",
       "    (Brew_Factory_Name): Merge(\n",
       "    )\n",
       "    (Style): Merge(\n",
       "    )\n",
       "    (ABV): Merge(\n",
       "    )\n",
       "  )\n",
       "  (attr_comparator): Merge(\n",
       "  )\n",
       "  (attr_merge): Merge(\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=900, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=900, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax()\n",
       "  )\n",
       "  (embed): ModuleMap(\n",
       "    (ltable_Beer_Name): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (ltable_Brew_Factory_Name): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (ltable_Style): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (ltable_ABV): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (rtable_Beer_Name): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (rtable_Brew_Factory_Name): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (rtable_Style): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "    (rtable_ABV): NoMeta(\n",
       "      (module): Embedding(1302, 300)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "#hybrid_model.run_train(train,valid,best_save_path='../../models/beer_balanced_hybrid.pth',epochs=30,pos_neg_ratio=4,batch_size=16)\n",
    "hybrid_model.load_state('../../models/beer_balanced_hybrid.pth')\n",
    "hybrid_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = dm.MatchingModel(attr_summarizer='attention')\n",
    "#attention_model.run_train(train,valid,best_save_path='../../models/beer_balanced_attention.pth',epochs=30,pos_neg_ratio=4,batch_size=16)\n",
    "attention_model.load_state('../../models/beer_balanced_attention.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.run_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = pd.read_csv('../../Structured/Beer/positives.csv')\n",
    "positives['rtable_Beer_Name'] = positives['rtable_Beer_Name']+\" imperial red ale\"\n",
    "positives['rtable_Beer_Name'] = positives['rtable_Beer_Name']+\" imperial red ale\"\n",
    "positives['ltable_Beer_Name'] = positives['ltable_Beer_Name']+\" imperial red ale\"\n",
    "positives.to_csv('temp/altered_positives.csv',index=False)\n",
    "positives.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled = dm.data.process_unlabeled('temp/altered_positives.csv',hybrid_model,ignore_columns=['id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = hybrid_model.run_prediction(unlabeled)\n",
    "pred[pred['match_score']>0.5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testneg_classifier_inputs,testneg_ids = return_layer_input('../../Structured/Beer/'\n",
    "                                                                         ,'test_negatives',32,hybrid_model,\n",
    "                                                                        hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_classifier_inputs,neg_ids = return_layer_input('../../Structured/Beer/'\n",
    "                                                                         ,'negatives',32,hybrid_model,\n",
    "                                                                        hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpos_classifier_inputs,testpos_ids = return_layer_input('../../Structured/Beer',\n",
    "                                                                       'test_positives',32,hybrid_model,\n",
    "                                                                       hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_classifier_inputs,pos_ids = return_layer_input('../../Structured/Beer',\n",
    "                                                                       'positives',32,hybrid_model,\n",
    "                                                                       hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_negative_classifier_inputs = list(map(lambda x: x[0],testneg_classifier_inputs))\n",
    "test_positive_classifier_inputs = list(map(lambda x: x[0],testpos_classifier_inputs))\n",
    "negative_classifier_inputs = list(map(lambda x: x[0],neg_classifier_inputs))\n",
    "positive_classifier_inputs = list(map(lambda x: x[0],pos_classifier_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes =['Beer_Name','Brew_Factory_Name','Style','ABV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_length = int((300*3)/len(attributes))\n",
    "classifier_length = int(attribute_length*len(attributes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sample = 0\n",
    "#each column of this matrix is related to a specific attribute\n",
    "negatives_ri_matrix = []\n",
    "for batch in test_negative_classifier_inputs:\n",
    "    for sample_index in range(len(batch)):\n",
    "        print('Processing sample number {}'.format(current_sample))\n",
    "        current_sample_ris = list(map(lambda att: find_smallest_variation_to_change(hybrid_model.classifier,\n",
    "                                                                                    classifier_length=classifier_length,\n",
    "                                                                                    attribute_length=attribute_length,\n",
    "                                                                                    input_matrix=batch,\n",
    "                                                                                    vector_index=sample_index,\n",
    "                                                                                    attributes=[attributes.index(att)]\n",
    "                                                                                    ,class_to_reach=1),attributes))\n",
    "        negatives_ri_matrix.append(current_sample_ris)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_norms_negative_samples = []\n",
    "for ri_list in negatives_ri_matrix:\n",
    "    ri_norms_negative_samples.append(list(map(lambda x:torch.norm(x).data[0],ri_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_variation_df = pd.DataFrame(data= ri_norms_negative_samples,columns=attributes)\n",
    "negatives_variation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_sums_negatives = negatives_variation_df.sum(numeric_only=True)\n",
    "ri_sums_negatives.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives_variation_df.to_csv('experiment-results/negatives_ri_extendedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive samples analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_sample = 0\n",
    "#each column of this matrix is related to a specific attribute\n",
    "positives_ri_matrix = []\n",
    "for batch in test_positive_classifier_inputs:\n",
    "    for sample_index in range(len(batch)):\n",
    "        print('Processing sample number {}'.format(current_sample))\n",
    "        current_sample_ris = list(map(lambda att: find_smallest_variation_to_change(hybrid_model.classifier,\n",
    "                                                                                    classifier_length=classifier_length,\n",
    "                                                                                    attribute_length=attribute_length,\n",
    "                                                                                    input_matrix=batch,\n",
    "                                                                                    vector_index=sample_index,\n",
    "                                                                                    attributes=[attributes.index(att)]\n",
    "                                                                                    ,class_to_reach=0),attributes))\n",
    "        positives_ri_matrix.append(current_sample_ris)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_norms_positives = []\n",
    "for ri_list in positives_ri_matrix:\n",
    "    ri_norms_positives.append(list(map(lambda x:torch.norm(x).data[0],ri_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_variation_df = pd.DataFrame(data= ri_norms_positives,columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri_sums_positives = positives_variation_df.sum(numeric_only=True)\n",
    "ri_sums_positives.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_variation_df.to_csv('experiment-results/ri_positives_extendedData.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find nearest neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = pd.read_csv('../../Structured/Beer/negatives.csv')\n",
    "positives = pd.read_csv('../../Structured/Beer/positives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities_functions.distance_measures import nearest_neighbour,nearest_neighbour_onAttribute\n",
    "#lista di tuple: vettore più vicino considerando tutti gli elementi e closer solo secondo un attributo\n",
    "negatives_closer_vectors = []\n",
    "i = 0\n",
    "for batch in test_negative_classifier_inputs:\n",
    "    for sample in batch:\n",
    "        current_sample_closer_vectors = list(map(lambda att: nearest_neighbour_onAttribute\n",
    "                                                 (sample+negatives_ri_matrix[i][attributes.index(att)]\n",
    "                                                                ,positive_classifier_inputs,attributes.index(att),\n",
    "                                                                attribute_length,'cosine'),attributes))\n",
    "        negatives_closer_vectors.append(current_sample_closer_vectors)\n",
    "        i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per ogni attributo trovo il più vicino\n",
    "positives_closer_vectors = []\n",
    "i = 0\n",
    "for batch in test_positive_classifier_inputs:\n",
    "    for sample in batch:\n",
    "        current_sample_closer_vectors = list(map(lambda att: nearest_neighbour_onAttribute\n",
    "                                                 (sample+positives_ri_matrix[i][attributes.index(att)]\n",
    "                                                                ,negative_classifier_inputs,attributes.index(att),\n",
    "                                                                attribute_length,'cosine'),attributes))\n",
    "        positives_closer_vectors.append(current_sample_closer_vectors)\n",
    "        i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df = pd.DataFrame(data= positives_closer_vectors,columns =attributes)\n",
    "positives_closer_vectors_df = positives_closer_vectors_df.applymap(lambda c:neg_ids[c])\n",
    "negatives_closer_vectors_df = pd.DataFrame(data = negatives_closer_vectors, columns = attributes)\n",
    "negatives_closer_vectors_df = negatives_closer_vectors_df.applymap(lambda c:pos_ids[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_closer_vectors_df['SampleID'] = testpos_ids\n",
    "negatives_closer_vectors_df['SampleID'] = testneg_ids\n",
    "positives_closer_vectors_df.to_csv('experiment-results/positives_nn_balanced.csv',index=False)\n",
    "negatives_closer_vectors_df.to_csv('experiment-results/negatives_nn_balanced.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities_functions.explainer import generateExplanations,analyze_valueDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpos_nn = pd.read_csv('experiment-results/positives_nn_balanced.csv')\n",
    "negatives = pd.read_csv('../../Structured/Beer/negatives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "The standard true positives are 65\n",
      "Photobomb Imperial Red Ale Fulton The Libertine Imperial Red Ale - Heaven Hill Rye Whiskey Barrel Aged\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "5\n",
      "Red Dirt Imperial Red Ale AleSmith YuleSmith &#40; Winter &#41; Imperial Red Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "2\n",
      "Ro Shampo Imperial Red Ale Ballast Point Tongue Buckler Imperial Red Ale - Bourbon Barrel Aged\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "4\n",
      "Ballistic Brewing Co. - Gorgon Red Ale Red Horn Coffee House and Brewing Company Red Horn Drink Well Red Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "16\n",
      "Freedom Bridge Amber Ale Bridge Ambleside Amber Ale - Pomegranate & Galena Hops\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.1 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "top5NN = generateExplanations(testpos_nn,5,negatives,\"Beer_Name\",hybrid_model,\n",
    "                    \"../../Structured/Beer/positives.csv\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testneg_nn = pd.read_csv('experiment-results/negatives_nn_balanced.csv')\n",
    "positives = pd.read_csv('../../Structured/Beer/positives.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "The standard true positives are 65\n",
      "Royal Amber Ale Kalamazoo Royal Amber Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "51\n",
      "Willoughby American Amber Ale Willoughby American Amber Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "52\n",
      "Radeau Red Ale Coopers Cave Radeau Red Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "51\n",
      "Amber Waves Ale Capitol City Amber Waves Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "51\n",
      "Hearthstone Red Rye Ale Hearthstone Red Rye Ale\n",
      "===>  PREDICT Epoch 3\n",
      "Finished Epoch 3 || Run Time:    0.2 | Load Time:    0.1 || F1:   0.00 | Prec:   0.00 | Rec:   0.00 || Ex/s:   0.00\n",
      "\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "top5NN_neg = generateExplanations(testneg_nn,5,positives,\"Beer_Name\",hybrid_model,\n",
    "                    \"../../Structured/Beer/positives.csv\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
