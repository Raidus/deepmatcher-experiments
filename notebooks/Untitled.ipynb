{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utils.intermediate_layer_extraction import return_layer_input\n",
    "import deepmatcher as dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "hybrid_model.load_state('../models/itunesamazon_hybrid.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmatcher.data import MatchingIterator\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _return_input(module,module_input,module_output):\n",
    "    global current_layer_input\n",
    "    current_layer_input = Variable(module_input[0].data.cuda(),requires_grad=True)\n",
    "\n",
    "\n",
    "    \n",
    "def _flat_list(l):\n",
    "    flat_list = []\n",
    "    for sublist in l:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n",
    "\n",
    "\n",
    "def return_layer_input(dataset_dir,dataset_name,batch_size,model,layer,device = 0):\n",
    "    dataset = dm.data.process(path=dataset_dir,train=dataset_name+'.csv',left_prefix='ltable_',right_prefix='rtable_',cache=dataset_name+'.pth')\n",
    "    dataset_tuple = dataset,\n",
    "    splits = MatchingIterator.splits(dataset_tuple,batch_size=batch_size, device = device)\n",
    "    tupleids = []\n",
    "    layer_inputs = []\n",
    "    hook = layer.register_forward_hook(_return_input)\n",
    "    for batch in splits[0]:\n",
    "        tupleids.append(batch.id)\n",
    "        model.forward(batch)\n",
    "        layer_inputs.append(current_layer_input)\n",
    "    hook.remove()\n",
    "    return layer_inputs,list(map(int,_flat_list(tupleids)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_classifier_hybrid,neg_ids = return_layer_input('../Structured/itunes-amazon','negatives',128,hybrid_model,\n",
    "                                                                        hybrid_model.classifier,device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = hybrid_model.attr_summarizers.Song_Name.register_forward_hook(print)\n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid(\n",
      "  (word_contextualizer): RNN(\n",
      "    (rnn_groups): ModuleList(\n",
      "      (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
      "    )\n",
      "    (dropouts): ModuleList(\n",
      "      (0): Dropout(p=0)\n",
      "    )\n",
      "    (bypass_networks): ModuleList(\n",
      "      (0): None\n",
      "    )\n",
      "    (input_dropout): NoMeta(\n",
      "      (module): Dropout(p=0)\n",
      "    )\n",
      "  )\n",
      "  (word_comparator): Attention(\n",
      "    (alignment_networks): ModuleList(\n",
      "      (0): AlignmentNetwork(\n",
      "        (transform): Transform(\n",
      "          (transforms): ModuleList(\n",
      "            (0): Linear(in_features=300, out_features=300, bias=True)\n",
      "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
      "          )\n",
      "          (bypass_networks): ModuleList(\n",
      "            (0): Bypass(\n",
      "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
      "            )\n",
      "            (1): Bypass(\n",
      "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (value_merge): Merge(\n",
      "    )\n",
      "    (comparison_merge): Merge(\n",
      "    )\n",
      "    (comparison_network): Transform(\n",
      "      (transforms): ModuleList(\n",
      "        (0): Linear(in_features=600, out_features=300, bias=True)\n",
      "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
      "      )\n",
      "      (bypass_networks): ModuleList(\n",
      "        (0): Bypass(\n",
      "          (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
      "        )\n",
      "        (1): Bypass(\n",
      "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (input_dropout): Dropout(p=0)\n",
      "    (transform_dropout): Dropout(p=0)\n",
      "    (score_dropout): Dropout(p=0)\n",
      "    (softmax): Softmax()\n",
      "  )\n",
      "  (word_aggregator): AttentionWithRNN(\n",
      "    (rnn): RNN(\n",
      "      (rnn_groups): ModuleList(\n",
      "        (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (dropouts): ModuleList(\n",
      "        (0): Dropout(p=0)\n",
      "      )\n",
      "      (bypass_networks): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (input_dropout): NoMeta(\n",
      "        (module): Dropout(p=0)\n",
      "      )\n",
      "    )\n",
      "    (rnn_pool): Pool(\n",
      "    )\n",
      "    (input_context_comparison_network): Transform(\n",
      "      (transforms): ModuleList(\n",
      "        (0): Linear(in_features=600, out_features=300, bias=True)\n",
      "      )\n",
      "      (bypass_networks): ModuleList(\n",
      "        (0): Bypass(\n",
      "          (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (scoring_network): Transform(\n",
      "      (transforms): ModuleList(\n",
      "        (0): Linear(in_features=300, out_features=1, bias=True)\n",
      "      )\n",
      "      (bypass_networks): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "    )\n",
      "    (input_dropout): Dropout(p=0)\n",
      "    (transform_dropout): Dropout(p=0)\n",
      "    (score_dropout): Dropout(p=0)\n",
      "    (softmax): Softmax()\n",
      "  )\n",
      ") (AttrTensor(data=Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      "  2.6283e-01  1.4665e-02 -1.9144e-01  ...   2.6782e-01  5.1616e-01  2.4732e-01\n",
      "  1.7271e-01  1.9410e-01  7.2030e-02  ...   1.2690e-01  2.3542e-01 -1.3771e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      "  8.5930e-03 -1.4561e-01 -9.3243e-02  ...   3.9384e-01  2.9511e-01  3.4725e-01\n",
      "  8.6750e-03 -8.5418e-01  1.1760e-01  ...  -2.4387e-01  3.4129e-02 -1.8458e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      " -9.2343e-02 -2.5227e-02 -1.9757e-02  ...   6.9460e-02 -2.1843e-02 -2.8049e-02\n",
      " -2.3309e-01 -1.5296e-01  1.8574e-01  ...   9.9402e-02  1.8834e-01  2.6413e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "... \n",
      "\n",
      "(125,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      " -2.3239e-01 -1.2607e-01  1.7417e-01  ...   5.0487e-01  1.4477e-01  1.2227e-03\n",
      " -2.3309e-01 -1.5296e-01  1.8574e-01  ...   9.9402e-02  1.8834e-01  2.6413e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "(126,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      " -2.3239e-01 -1.2607e-01  1.7417e-01  ...   5.0487e-01  1.4477e-01  1.2227e-03\n",
      " -2.3309e-01 -1.5296e-01  1.8574e-01  ...   9.9402e-02  1.8834e-01  2.6413e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "(127,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      " -6.9431e-02  1.7491e-01  2.4622e-01  ...   4.5718e-01  9.1984e-01 -1.6930e-01\n",
      "  4.7810e-03  1.5530e-01 -3.2802e-03  ...  -1.3432e-02  2.4341e-01  8.6841e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  1.9131e-01 -2.4213e-01  1.4122e-01  ...  -4.7967e-01 -3.1254e-01  2.7801e-01\n",
      "  4.9489e-01  3.4278e-01  2.6332e-01  ...   4.0024e-01  2.3326e-01 -1.3212e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "[torch.FloatTensor of size 128x21x300]\n",
      ", lengths=\n",
      " 12\n",
      " 10\n",
      "  9\n",
      " 10\n",
      " 11\n",
      " 14\n",
      "  9\n",
      " 11\n",
      "  7\n",
      " 11\n",
      " 11\n",
      " 15\n",
      " 11\n",
      " 18\n",
      " 11\n",
      " 21\n",
      " 10\n",
      " 11\n",
      "  7\n",
      " 12\n",
      " 11\n",
      "  6\n",
      " 14\n",
      " 18\n",
      " 10\n",
      " 11\n",
      " 13\n",
      " 10\n",
      " 14\n",
      " 12\n",
      "  8\n",
      " 14\n",
      " 15\n",
      "  9\n",
      " 11\n",
      " 18\n",
      " 14\n",
      "  9\n",
      " 14\n",
      " 14\n",
      " 19\n",
      " 10\n",
      " 18\n",
      " 11\n",
      "  9\n",
      " 14\n",
      " 10\n",
      " 11\n",
      " 11\n",
      "  9\n",
      " 19\n",
      "  5\n",
      " 14\n",
      " 10\n",
      "  8\n",
      "  6\n",
      "  9\n",
      " 14\n",
      "  6\n",
      "  6\n",
      "  8\n",
      "  6\n",
      " 12\n",
      " 15\n",
      " 14\n",
      " 11\n",
      " 18\n",
      " 18\n",
      "  8\n",
      " 18\n",
      " 11\n",
      " 12\n",
      "  7\n",
      "  9\n",
      "  9\n",
      " 17\n",
      " 12\n",
      " 14\n",
      "  8\n",
      " 18\n",
      " 10\n",
      " 10\n",
      " 18\n",
      " 14\n",
      " 12\n",
      "  8\n",
      "  7\n",
      " 14\n",
      " 14\n",
      " 10\n",
      " 19\n",
      " 13\n",
      " 19\n",
      "  9\n",
      " 16\n",
      " 11\n",
      " 15\n",
      "  7\n",
      " 14\n",
      " 10\n",
      "  7\n",
      " 14\n",
      "  4\n",
      " 10\n",
      "  9\n",
      "  9\n",
      "  7\n",
      "  9\n",
      " 15\n",
      " 18\n",
      " 14\n",
      " 18\n",
      " 18\n",
      "  7\n",
      " 10\n",
      " 12\n",
      " 10\n",
      " 10\n",
      " 11\n",
      " 15\n",
      "  9\n",
      " 11\n",
      " 14\n",
      " 10\n",
      " 12\n",
      " 14\n",
      " 14\n",
      " 20\n",
      "[torch.LongTensor of size 128]\n",
      ", word_probs=\n",
      " 0.0455  0.0001  0.0003  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0035  0.0057  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0003  0.0417  ...   0.4702  0.4702  0.4702\n",
      "          ...             ⋱             ...          \n",
      " 0.0455  0.0047  0.0417  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0047  0.0417  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0009  0.0025  ...   0.0161  0.0455  0.4702\n",
      "[torch.FloatTensor of size 128x21]\n",
      ", pc=\n",
      "-0.0281\n",
      "-0.0208\n",
      "-0.0300\n",
      " 0.0465\n",
      "-0.0706\n",
      "-0.0108\n",
      " 0.0218\n",
      "-0.0143\n",
      " 0.0205\n",
      " 0.0339\n",
      " 0.0406\n",
      " 0.0305\n",
      "-0.0291\n",
      "-0.0459\n",
      " 0.0268\n",
      "-0.0555\n",
      "-0.0197\n",
      " 0.0208\n",
      "-0.0237\n",
      " 0.0928\n",
      "-0.0564\n",
      " 0.0788\n",
      "-0.0606\n",
      "-0.0555\n",
      "-0.0245\n",
      "-0.0244\n",
      "-0.0075\n",
      "-0.0022\n",
      " 0.0365\n",
      " 0.0535\n",
      "-0.0279\n",
      " 0.1184\n",
      "-0.0721\n",
      " 0.0442\n",
      " 0.0171\n",
      "-0.0265\n",
      " 0.0308\n",
      "-0.0554\n",
      " 0.0159\n",
      "-0.0682\n",
      " 0.0216\n",
      "-0.0014\n",
      "-0.0355\n",
      " 0.0698\n",
      " 0.0307\n",
      "-0.0052\n",
      "-0.0004\n",
      "-0.0050\n",
      "-0.0250\n",
      " 0.0065\n",
      " 0.0410\n",
      "-0.0638\n",
      " 0.0231\n",
      "-0.0057\n",
      " 0.0137\n",
      " 0.0448\n",
      " 0.0509\n",
      " 0.0259\n",
      " 0.0036\n",
      " 0.1008\n",
      " 0.0408\n",
      " 0.0157\n",
      " 0.1017\n",
      "-0.0090\n",
      "-0.0646\n",
      "-0.0150\n",
      "-0.0037\n",
      " 0.0506\n",
      "-0.0428\n",
      " 0.0002\n",
      " 0.0207\n",
      "-0.0127\n",
      " 0.0788\n",
      "-0.0474\n",
      "-0.0326\n",
      " 0.0619\n",
      " 0.1104\n",
      " 0.0029\n",
      "-0.0348\n",
      "-0.0026\n",
      " 0.0410\n",
      "-0.0037\n",
      "-0.0121\n",
      " 0.0356\n",
      "-0.0174\n",
      "-0.0432\n",
      "-0.0421\n",
      "-0.0162\n",
      " 0.0509\n",
      " 0.0253\n",
      " 0.0243\n",
      "-0.0385\n",
      " 0.0854\n",
      "-0.0280\n",
      " 0.0591\n",
      " 0.0602\n",
      " 0.0063\n",
      "-0.0040\n",
      "-0.0251\n",
      "-0.0431\n",
      " 0.0395\n",
      "-0.0419\n",
      " 0.0468\n",
      "-0.0186\n",
      "-0.0350\n",
      "-0.0359\n",
      "-0.0876\n",
      " 0.0384\n",
      " 0.0524\n",
      "-0.0332\n",
      " 0.0060\n",
      "-0.0038\n",
      "-0.0199\n",
      "-0.0389\n",
      "-0.0398\n",
      "-0.0468\n",
      " 0.0801\n",
      " 0.0219\n",
      "-0.0605\n",
      " 0.0655\n",
      " 0.1346\n",
      " 0.0226\n",
      "-0.0062\n",
      " 0.1607\n",
      " 0.0036\n",
      " 0.0017\n",
      " 0.0162\n",
      " 0.0502\n",
      " 0.0420\n",
      " 0.0758\n",
      "-0.0228\n",
      " 0.0700\n",
      "-0.0377\n",
      " 0.0774\n",
      " 0.0400\n",
      "-0.0068\n",
      "-0.0423\n",
      "-0.0102\n",
      " 0.0140\n",
      " 0.0763\n",
      " 0.0216\n",
      " 0.0813\n",
      " 0.0794\n",
      " 0.0142\n",
      "-0.0352\n",
      " 0.0999\n",
      "-0.0034\n",
      "-0.0515\n",
      " 0.0003\n",
      " 0.0030\n",
      " 0.1069\n",
      "-0.0809\n",
      "-0.0484\n",
      "-0.0595\n",
      "-0.0473\n",
      " 0.0052\n",
      "-0.0260\n",
      "-0.0535\n",
      " 0.0587\n",
      " 0.0211\n",
      " 0.0553\n",
      " 0.0669\n",
      "-0.0908\n",
      " 0.0283\n",
      " 0.0564\n",
      " 0.0324\n",
      "-0.0413\n",
      "-0.0562\n",
      " 0.1341\n",
      " 0.0399\n",
      "-0.0837\n",
      "-0.0936\n",
      "-0.1512\n",
      "-0.0262\n",
      "-0.0228\n",
      " 0.1287\n",
      "-0.0611\n",
      " 0.0275\n",
      "-0.0247\n",
      "-0.0854\n",
      " 0.0535\n",
      "-0.0684\n",
      " 0.0340\n",
      " 0.0493\n",
      "-0.0726\n",
      " 0.1299\n",
      " 0.0163\n",
      "-0.0817\n",
      " 0.0974\n",
      "-0.0162\n",
      "-0.0215\n",
      "-0.1229\n",
      " 0.0539\n",
      " 0.1047\n",
      "-0.1195\n",
      "-0.0068\n",
      "-0.0193\n",
      " 0.0247\n",
      "-0.1591\n",
      "-0.0735\n",
      " 0.0853\n",
      " 0.0234\n",
      " 0.0602\n",
      "-0.0191\n",
      " 0.0155\n",
      "-0.1050\n",
      "-0.1081\n",
      "-0.0068\n",
      " 0.1523\n",
      "-0.0038\n",
      " 0.2530\n",
      "-0.0179\n",
      "-0.0279\n",
      "-0.1282\n",
      " 0.0036\n",
      "-0.0396\n",
      "-0.0257\n",
      "-0.1474\n",
      "-0.0827\n",
      " 0.0288\n",
      "-0.0664\n",
      "-0.0799\n",
      "-0.0517\n",
      " 0.0818\n",
      "-0.0040\n",
      " 0.0223\n",
      "-0.0658\n",
      "-0.0839\n",
      " 0.0160\n",
      " 0.0365\n",
      " 0.0771\n",
      " 0.0639\n",
      "-0.0104\n",
      "-0.0255\n",
      "-0.0082\n",
      " 0.0182\n",
      " 0.0022\n",
      " 0.0389\n",
      "-0.0609\n",
      "-0.0414\n",
      "-0.0124\n",
      " 0.0389\n",
      " 0.0363\n",
      " 0.0552\n",
      "-0.0424\n",
      " 0.0198\n",
      " 0.0216\n",
      " 0.0106\n",
      "-0.0244\n",
      "-0.0162\n",
      " 0.0442\n",
      "-0.0463\n",
      "-0.0659\n",
      "-0.0047\n",
      " 0.0221\n",
      "-0.0013\n",
      "-0.0242\n",
      "-0.0764\n",
      " 0.0648\n",
      "-0.0023\n",
      " 0.0199\n",
      " 0.0899\n",
      " 0.0615\n",
      "-0.0571\n",
      "-0.0746\n",
      "-0.0319\n",
      "-0.0264\n",
      " 0.0550\n",
      "-0.0031\n",
      "-0.0621\n",
      "-0.0838\n",
      "-0.0272\n",
      " 0.0791\n",
      " 0.0335\n",
      "-0.0875\n",
      "-0.0890\n",
      " 0.0987\n",
      " 0.0910\n",
      "-0.0132\n",
      "-0.0196\n",
      " 0.0773\n",
      " 0.0435\n",
      "-0.0189\n",
      " 0.0431\n",
      " 0.0500\n",
      " 0.0100\n",
      " 0.0674\n",
      " 0.0938\n",
      "-0.0190\n",
      " 0.0399\n",
      " 0.0377\n",
      "-0.0161\n",
      " 0.0594\n",
      " 0.0027\n",
      " 0.0193\n",
      "-0.0703\n",
      "-0.0280\n",
      " 0.0887\n",
      " 0.0909\n",
      " 0.0183\n",
      "[torch.FloatTensor of size 300]\n",
      "), AttrTensor(data=Variable containing:\n",
      "( 0 ,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      "  2.6283e-01  1.4665e-02 -1.9144e-01  ...   2.6782e-01  5.1616e-01  2.4732e-01\n",
      "  1.7271e-01  1.9410e-01  7.2030e-02  ...   1.2690e-01  2.3542e-01 -1.3771e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "( 1 ,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      " -6.5334e-02 -9.3031e-02 -1.7571e-02  ...   1.6642e-01 -1.3079e-01  3.5397e-02\n",
      "  2.0007e-01  9.5481e-02 -1.9302e-01  ...   4.4481e-01  3.6663e-01  1.9766e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "( 2 ,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      "  1.1958e-01  1.5844e-01  8.0985e-02  ...   2.8777e-01  3.6150e-01 -1.9605e-01\n",
      " -1.8707e-01 -1.0160e-01  3.9349e-02  ...   1.6853e-01  2.5261e-01  3.9157e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "... \n",
      "\n",
      "(125,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      " -7.2697e-02 -1.8412e-02 -1.8324e-01  ...   1.8840e-01 -4.8356e-03  1.9498e-01\n",
      "  8.6750e-03 -8.5418e-01  1.1760e-01  ...  -2.4387e-01  3.4129e-02 -1.8458e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "(126,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      "  2.5967e-02 -1.1775e-03 -2.1643e-01  ...  -3.7480e-01  3.3749e-01  3.2355e-01\n",
      "  4.7810e-03  1.5530e-01 -3.2802e-03  ...  -1.3432e-02  2.4341e-01  8.6841e-02\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "\n",
      "(127,.,.) = \n",
      "  2.0794e-02 -6.4424e-02  3.3462e-04  ...  -3.4522e-01 -5.7764e-02 -5.3072e-02\n",
      "  1.0633e-01  8.8146e-02  1.2233e-01  ...   1.2054e-01  8.2242e-01 -9.7147e-02\n",
      " -1.7998e-01 -1.5551e-02  3.3463e-02  ...   2.9691e-01  2.2296e-01 -3.3318e-01\n",
      "                 ...                   ⋱                   ...                \n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "  6.4957e-02 -5.7659e-02 -6.5004e-02  ...   2.3398e-01  4.6927e-02  1.9378e-01\n",
      "[torch.FloatTensor of size 128x22x300]\n",
      ", lengths=\n",
      " 10\n",
      " 14\n",
      " 10\n",
      " 11\n",
      " 14\n",
      " 15\n",
      " 10\n",
      "  9\n",
      " 20\n",
      "  9\n",
      " 11\n",
      " 15\n",
      "  7\n",
      " 16\n",
      " 17\n",
      "  8\n",
      " 11\n",
      " 13\n",
      " 10\n",
      " 12\n",
      " 10\n",
      "  3\n",
      " 15\n",
      "  9\n",
      " 13\n",
      " 14\n",
      "  9\n",
      " 13\n",
      "  6\n",
      " 14\n",
      "  9\n",
      " 11\n",
      " 13\n",
      "  8\n",
      "  7\n",
      " 13\n",
      " 14\n",
      " 13\n",
      " 19\n",
      "  9\n",
      " 14\n",
      " 14\n",
      " 13\n",
      " 17\n",
      " 19\n",
      " 12\n",
      " 12\n",
      " 13\n",
      " 11\n",
      "  9\n",
      " 14\n",
      "  6\n",
      " 15\n",
      " 13\n",
      "  8\n",
      " 11\n",
      " 11\n",
      " 10\n",
      "  8\n",
      " 21\n",
      " 14\n",
      " 10\n",
      " 14\n",
      " 12\n",
      " 14\n",
      "  8\n",
      " 15\n",
      " 20\n",
      "  8\n",
      " 19\n",
      " 15\n",
      "  9\n",
      "  7\n",
      " 15\n",
      "  4\n",
      " 11\n",
      " 10\n",
      " 15\n",
      " 11\n",
      " 13\n",
      " 13\n",
      " 11\n",
      " 12\n",
      " 15\n",
      " 14\n",
      " 11\n",
      "  7\n",
      " 14\n",
      " 19\n",
      " 16\n",
      " 12\n",
      " 22\n",
      "  6\n",
      "  9\n",
      "  9\n",
      "  8\n",
      " 13\n",
      " 11\n",
      "  9\n",
      " 18\n",
      "  7\n",
      " 12\n",
      "  6\n",
      " 14\n",
      " 14\n",
      " 10\n",
      "  8\n",
      " 10\n",
      " 15\n",
      " 19\n",
      " 18\n",
      " 22\n",
      " 15\n",
      " 16\n",
      " 13\n",
      " 11\n",
      " 10\n",
      "  8\n",
      "  9\n",
      "  9\n",
      " 10\n",
      " 10\n",
      " 14\n",
      " 18\n",
      "  9\n",
      " 13\n",
      " 13\n",
      "  9\n",
      "[torch.LongTensor of size 128]\n",
      ", word_probs=\n",
      " 0.0312  0.0001  0.0005  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0033  0.0003  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0001  0.0053  ...   0.6172  0.6172  0.6172\n",
      "          ...             ⋱             ...          \n",
      " 0.0312  0.0002  0.0026  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0005  0.0010  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0007  0.0004  ...   0.6172  0.6172  0.6172\n",
      "[torch.FloatTensor of size 128x22]\n",
      ", pc=\n",
      "-0.0293\n",
      "-0.0238\n",
      "-0.0300\n",
      " 0.0457\n",
      "-0.0648\n",
      "-0.0081\n",
      " 0.0131\n",
      "-0.0109\n",
      " 0.0323\n",
      " 0.0220\n",
      " 0.0419\n",
      " 0.0286\n",
      "-0.0330\n",
      "-0.0504\n",
      " 0.0224\n",
      "-0.0672\n",
      "-0.0146\n",
      " 0.0135\n",
      "-0.0188\n",
      " 0.0931\n",
      "-0.0591\n",
      " 0.0672\n",
      "-0.0529\n",
      "-0.0544\n",
      "-0.0187\n",
      "-0.0325\n",
      "-0.0136\n",
      " 0.0032\n",
      " 0.0258\n",
      " 0.0538\n",
      "-0.0311\n",
      " 0.1236\n",
      "-0.0623\n",
      " 0.0431\n",
      " 0.0185\n",
      "-0.0313\n",
      " 0.0278\n",
      "-0.0490\n",
      " 0.0151\n",
      "-0.0598\n",
      " 0.0259\n",
      "-0.0009\n",
      "-0.0189\n",
      " 0.0682\n",
      " 0.0154\n",
      " 0.0038\n",
      " 0.0016\n",
      "-0.0049\n",
      "-0.0195\n",
      " 0.0006\n",
      " 0.0477\n",
      "-0.0645\n",
      " 0.0178\n",
      "-0.0052\n",
      " 0.0047\n",
      " 0.0620\n",
      " 0.0517\n",
      " 0.0265\n",
      "-0.0031\n",
      " 0.0951\n",
      " 0.0418\n",
      " 0.0178\n",
      " 0.1043\n",
      "-0.0060\n",
      "-0.0589\n",
      "-0.0161\n",
      "-0.0036\n",
      " 0.0471\n",
      "-0.0402\n",
      "-0.0009\n",
      " 0.0162\n",
      "-0.0032\n",
      " 0.0781\n",
      "-0.0482\n",
      "-0.0409\n",
      " 0.0630\n",
      " 0.1015\n",
      " 0.0019\n",
      "-0.0332\n",
      " 0.0060\n",
      " 0.0332\n",
      "-0.0096\n",
      "-0.0116\n",
      " 0.0436\n",
      "-0.0089\n",
      "-0.0359\n",
      "-0.0392\n",
      "-0.0064\n",
      " 0.0452\n",
      " 0.0251\n",
      " 0.0186\n",
      "-0.0402\n",
      " 0.0813\n",
      "-0.0337\n",
      " 0.0600\n",
      " 0.0500\n",
      " 0.0038\n",
      "-0.0028\n",
      "-0.0266\n",
      "-0.0355\n",
      " 0.0393\n",
      "-0.0479\n",
      " 0.0524\n",
      "-0.0127\n",
      "-0.0354\n",
      "-0.0375\n",
      "-0.0772\n",
      " 0.0341\n",
      " 0.0501\n",
      "-0.0347\n",
      " 0.0097\n",
      "-0.0048\n",
      "-0.0249\n",
      "-0.0396\n",
      "-0.0462\n",
      "-0.0467\n",
      " 0.0780\n",
      " 0.0190\n",
      "-0.0662\n",
      " 0.0707\n",
      " 0.1265\n",
      " 0.0105\n",
      "-0.0076\n",
      " 0.1652\n",
      " 0.0095\n",
      "-0.0004\n",
      " 0.0085\n",
      " 0.0581\n",
      " 0.0479\n",
      " 0.0695\n",
      "-0.0174\n",
      " 0.0723\n",
      "-0.0321\n",
      " 0.0770\n",
      " 0.0450\n",
      "-0.0101\n",
      "-0.0465\n",
      "-0.0048\n",
      " 0.0126\n",
      " 0.0771\n",
      " 0.0263\n",
      " 0.0770\n",
      " 0.0781\n",
      " 0.0143\n",
      "-0.0391\n",
      " 0.0952\n",
      "-0.0082\n",
      "-0.0490\n",
      "-0.0114\n",
      " 0.0072\n",
      " 0.1072\n",
      "-0.0806\n",
      "-0.0495\n",
      "-0.0714\n",
      "-0.0404\n",
      " 0.0043\n",
      "-0.0167\n",
      "-0.0521\n",
      " 0.0570\n",
      " 0.0205\n",
      " 0.0642\n",
      " 0.0612\n",
      "-0.0909\n",
      " 0.0273\n",
      " 0.0617\n",
      " 0.0290\n",
      "-0.0418\n",
      "-0.0492\n",
      " 0.1320\n",
      " 0.0569\n",
      "-0.0812\n",
      "-0.0963\n",
      "-0.1514\n",
      "-0.0287\n",
      "-0.0308\n",
      " 0.1220\n",
      "-0.0565\n",
      " 0.0192\n",
      "-0.0239\n",
      "-0.0805\n",
      " 0.0497\n",
      "-0.0723\n",
      " 0.0430\n",
      " 0.0444\n",
      "-0.0664\n",
      " 0.1304\n",
      " 0.0146\n",
      "-0.0835\n",
      " 0.1019\n",
      "-0.0104\n",
      "-0.0315\n",
      "-0.1260\n",
      " 0.0560\n",
      " 0.1042\n",
      "-0.1290\n",
      "-0.0128\n",
      "-0.0268\n",
      " 0.0263\n",
      "-0.1687\n",
      "-0.0807\n",
      " 0.0819\n",
      " 0.0281\n",
      " 0.0675\n",
      "-0.0231\n",
      " 0.0099\n",
      "-0.1055\n",
      "-0.1087\n",
      "-0.0130\n",
      " 0.1551\n",
      " 0.0006\n",
      " 0.2553\n",
      "-0.0152\n",
      "-0.0274\n",
      "-0.1316\n",
      " 0.0048\n",
      "-0.0476\n",
      "-0.0320\n",
      "-0.1416\n",
      "-0.0778\n",
      " 0.0291\n",
      "-0.0572\n",
      "-0.0832\n",
      "-0.0571\n",
      " 0.0819\n",
      "-0.0042\n",
      " 0.0155\n",
      "-0.0676\n",
      "-0.0856\n",
      " 0.0197\n",
      " 0.0345\n",
      " 0.0790\n",
      " 0.0627\n",
      "-0.0077\n",
      "-0.0260\n",
      "-0.0069\n",
      " 0.0138\n",
      " 0.0037\n",
      " 0.0419\n",
      "-0.0663\n",
      "-0.0455\n",
      "-0.0091\n",
      " 0.0334\n",
      " 0.0302\n",
      " 0.0615\n",
      "-0.0337\n",
      " 0.0144\n",
      " 0.0276\n",
      " 0.0037\n",
      "-0.0270\n",
      "-0.0214\n",
      " 0.0380\n",
      "-0.0490\n",
      "-0.0610\n",
      "-0.0114\n",
      " 0.0212\n",
      "-0.0043\n",
      "-0.0252\n",
      "-0.0794\n",
      " 0.0694\n",
      "-0.0018\n",
      " 0.0163\n",
      " 0.0890\n",
      " 0.0528\n",
      "-0.0654\n",
      "-0.0761\n",
      "-0.0409\n",
      "-0.0324\n",
      " 0.0528\n",
      " 0.0056\n",
      "-0.0602\n",
      "-0.0799\n",
      "-0.0274\n",
      " 0.0790\n",
      " 0.0300\n",
      "-0.0781\n",
      "-0.0925\n",
      " 0.0997\n",
      " 0.0885\n",
      "-0.0069\n",
      "-0.0220\n",
      " 0.0879\n",
      " 0.0321\n",
      "-0.0182\n",
      " 0.0468\n",
      " 0.0564\n",
      " 0.0137\n",
      " 0.0656\n",
      " 0.0846\n",
      "-0.0195\n",
      " 0.0395\n",
      " 0.0375\n",
      "-0.0157\n",
      " 0.0535\n",
      " 0.0050\n",
      " 0.0189\n",
      "-0.0691\n",
      "-0.0334\n",
      " 0.0911\n",
      " 0.0988\n",
      " 0.0137\n",
      "[torch.FloatTensor of size 300]\n",
      ")) (AttrTensor(data=Variable containing:\n",
      " 4.1826e-02  1.4610e-01  1.0509e-01  ...   1.6336e-01 -1.9224e-02 -2.1564e-01\n",
      " 1.2824e-01  2.2305e-01  1.0101e-02  ...   5.6337e-03  3.6842e-02 -2.3478e-01\n",
      " 2.2384e-01  2.2715e-01  1.6497e-02  ...   5.6013e-02  1.8087e-02 -2.7221e-01\n",
      "                ...                   ⋱                   ...                \n",
      " 3.6123e-02  1.8048e-01 -5.8060e-03  ...   2.4595e-01 -7.6363e-03 -2.2523e-01\n",
      "-1.6201e-02  2.1464e-01 -1.7333e-02  ...   2.3257e-01  1.4881e-02 -2.2141e-01\n",
      " 1.6115e-02  1.6663e-01  4.7569e-02  ...   2.3145e-01  4.4745e-02 -2.0346e-01\n",
      "[torch.FloatTensor of size 128x300]\n",
      ", lengths=\n",
      " 12\n",
      " 10\n",
      "  9\n",
      " 10\n",
      " 11\n",
      " 14\n",
      "  9\n",
      " 11\n",
      "  7\n",
      " 11\n",
      " 11\n",
      " 15\n",
      " 11\n",
      " 18\n",
      " 11\n",
      " 21\n",
      " 10\n",
      " 11\n",
      "  7\n",
      " 12\n",
      " 11\n",
      "  6\n",
      " 14\n",
      " 18\n",
      " 10\n",
      " 11\n",
      " 13\n",
      " 10\n",
      " 14\n",
      " 12\n",
      "  8\n",
      " 14\n",
      " 15\n",
      "  9\n",
      " 11\n",
      " 18\n",
      " 14\n",
      "  9\n",
      " 14\n",
      " 14\n",
      " 19\n",
      " 10\n",
      " 18\n",
      " 11\n",
      "  9\n",
      " 14\n",
      " 10\n",
      " 11\n",
      " 11\n",
      "  9\n",
      " 19\n",
      "  5\n",
      " 14\n",
      " 10\n",
      "  8\n",
      "  6\n",
      "  9\n",
      " 14\n",
      "  6\n",
      "  6\n",
      "  8\n",
      "  6\n",
      " 12\n",
      " 15\n",
      " 14\n",
      " 11\n",
      " 18\n",
      " 18\n",
      "  8\n",
      " 18\n",
      " 11\n",
      " 12\n",
      "  7\n",
      "  9\n",
      "  9\n",
      " 17\n",
      " 12\n",
      " 14\n",
      "  8\n",
      " 18\n",
      " 10\n",
      " 10\n",
      " 18\n",
      " 14\n",
      " 12\n",
      "  8\n",
      "  7\n",
      " 14\n",
      " 14\n",
      " 10\n",
      " 19\n",
      " 13\n",
      " 19\n",
      "  9\n",
      " 16\n",
      " 11\n",
      " 15\n",
      "  7\n",
      " 14\n",
      " 10\n",
      "  7\n",
      " 14\n",
      "  4\n",
      " 10\n",
      "  9\n",
      "  9\n",
      "  7\n",
      "  9\n",
      " 15\n",
      " 18\n",
      " 14\n",
      " 18\n",
      " 18\n",
      "  7\n",
      " 10\n",
      " 12\n",
      " 10\n",
      " 10\n",
      " 11\n",
      " 15\n",
      "  9\n",
      " 11\n",
      " 14\n",
      " 10\n",
      " 12\n",
      " 14\n",
      " 14\n",
      " 20\n",
      "[torch.LongTensor of size 128]\n",
      ", word_probs=\n",
      " 0.0455  0.0001  0.0003  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0035  0.0057  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0003  0.0417  ...   0.4702  0.4702  0.4702\n",
      "          ...             ⋱             ...          \n",
      " 0.0455  0.0047  0.0417  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0047  0.0417  ...   0.4702  0.4702  0.4702\n",
      " 0.0455  0.0009  0.0025  ...   0.0161  0.0455  0.4702\n",
      "[torch.FloatTensor of size 128x21]\n",
      ", pc=\n",
      "-0.0281\n",
      "-0.0208\n",
      "-0.0300\n",
      " 0.0465\n",
      "-0.0706\n",
      "-0.0108\n",
      " 0.0218\n",
      "-0.0143\n",
      " 0.0205\n",
      " 0.0339\n",
      " 0.0406\n",
      " 0.0305\n",
      "-0.0291\n",
      "-0.0459\n",
      " 0.0268\n",
      "-0.0555\n",
      "-0.0197\n",
      " 0.0208\n",
      "-0.0237\n",
      " 0.0928\n",
      "-0.0564\n",
      " 0.0788\n",
      "-0.0606\n",
      "-0.0555\n",
      "-0.0245\n",
      "-0.0244\n",
      "-0.0075\n",
      "-0.0022\n",
      " 0.0365\n",
      " 0.0535\n",
      "-0.0279\n",
      " 0.1184\n",
      "-0.0721\n",
      " 0.0442\n",
      " 0.0171\n",
      "-0.0265\n",
      " 0.0308\n",
      "-0.0554\n",
      " 0.0159\n",
      "-0.0682\n",
      " 0.0216\n",
      "-0.0014\n",
      "-0.0355\n",
      " 0.0698\n",
      " 0.0307\n",
      "-0.0052\n",
      "-0.0004\n",
      "-0.0050\n",
      "-0.0250\n",
      " 0.0065\n",
      " 0.0410\n",
      "-0.0638\n",
      " 0.0231\n",
      "-0.0057\n",
      " 0.0137\n",
      " 0.0448\n",
      " 0.0509\n",
      " 0.0259\n",
      " 0.0036\n",
      " 0.1008\n",
      " 0.0408\n",
      " 0.0157\n",
      " 0.1017\n",
      "-0.0090\n",
      "-0.0646\n",
      "-0.0150\n",
      "-0.0037\n",
      " 0.0506\n",
      "-0.0428\n",
      " 0.0002\n",
      " 0.0207\n",
      "-0.0127\n",
      " 0.0788\n",
      "-0.0474\n",
      "-0.0326\n",
      " 0.0619\n",
      " 0.1104\n",
      " 0.0029\n",
      "-0.0348\n",
      "-0.0026\n",
      " 0.0410\n",
      "-0.0037\n",
      "-0.0121\n",
      " 0.0356\n",
      "-0.0174\n",
      "-0.0432\n",
      "-0.0421\n",
      "-0.0162\n",
      " 0.0509\n",
      " 0.0253\n",
      " 0.0243\n",
      "-0.0385\n",
      " 0.0854\n",
      "-0.0280\n",
      " 0.0591\n",
      " 0.0602\n",
      " 0.0063\n",
      "-0.0040\n",
      "-0.0251\n",
      "-0.0431\n",
      " 0.0395\n",
      "-0.0419\n",
      " 0.0468\n",
      "-0.0186\n",
      "-0.0350\n",
      "-0.0359\n",
      "-0.0876\n",
      " 0.0384\n",
      " 0.0524\n",
      "-0.0332\n",
      " 0.0060\n",
      "-0.0038\n",
      "-0.0199\n",
      "-0.0389\n",
      "-0.0398\n",
      "-0.0468\n",
      " 0.0801\n",
      " 0.0219\n",
      "-0.0605\n",
      " 0.0655\n",
      " 0.1346\n",
      " 0.0226\n",
      "-0.0062\n",
      " 0.1607\n",
      " 0.0036\n",
      " 0.0017\n",
      " 0.0162\n",
      " 0.0502\n",
      " 0.0420\n",
      " 0.0758\n",
      "-0.0228\n",
      " 0.0700\n",
      "-0.0377\n",
      " 0.0774\n",
      " 0.0400\n",
      "-0.0068\n",
      "-0.0423\n",
      "-0.0102\n",
      " 0.0140\n",
      " 0.0763\n",
      " 0.0216\n",
      " 0.0813\n",
      " 0.0794\n",
      " 0.0142\n",
      "-0.0352\n",
      " 0.0999\n",
      "-0.0034\n",
      "-0.0515\n",
      " 0.0003\n",
      " 0.0030\n",
      " 0.1069\n",
      "-0.0809\n",
      "-0.0484\n",
      "-0.0595\n",
      "-0.0473\n",
      " 0.0052\n",
      "-0.0260\n",
      "-0.0535\n",
      " 0.0587\n",
      " 0.0211\n",
      " 0.0553\n",
      " 0.0669\n",
      "-0.0908\n",
      " 0.0283\n",
      " 0.0564\n",
      " 0.0324\n",
      "-0.0413\n",
      "-0.0562\n",
      " 0.1341\n",
      " 0.0399\n",
      "-0.0837\n",
      "-0.0936\n",
      "-0.1512\n",
      "-0.0262\n",
      "-0.0228\n",
      " 0.1287\n",
      "-0.0611\n",
      " 0.0275\n",
      "-0.0247\n",
      "-0.0854\n",
      " 0.0535\n",
      "-0.0684\n",
      " 0.0340\n",
      " 0.0493\n",
      "-0.0726\n",
      " 0.1299\n",
      " 0.0163\n",
      "-0.0817\n",
      " 0.0974\n",
      "-0.0162\n",
      "-0.0215\n",
      "-0.1229\n",
      " 0.0539\n",
      " 0.1047\n",
      "-0.1195\n",
      "-0.0068\n",
      "-0.0193\n",
      " 0.0247\n",
      "-0.1591\n",
      "-0.0735\n",
      " 0.0853\n",
      " 0.0234\n",
      " 0.0602\n",
      "-0.0191\n",
      " 0.0155\n",
      "-0.1050\n",
      "-0.1081\n",
      "-0.0068\n",
      " 0.1523\n",
      "-0.0038\n",
      " 0.2530\n",
      "-0.0179\n",
      "-0.0279\n",
      "-0.1282\n",
      " 0.0036\n",
      "-0.0396\n",
      "-0.0257\n",
      "-0.1474\n",
      "-0.0827\n",
      " 0.0288\n",
      "-0.0664\n",
      "-0.0799\n",
      "-0.0517\n",
      " 0.0818\n",
      "-0.0040\n",
      " 0.0223\n",
      "-0.0658\n",
      "-0.0839\n",
      " 0.0160\n",
      " 0.0365\n",
      " 0.0771\n",
      " 0.0639\n",
      "-0.0104\n",
      "-0.0255\n",
      "-0.0082\n",
      " 0.0182\n",
      " 0.0022\n",
      " 0.0389\n",
      "-0.0609\n",
      "-0.0414\n",
      "-0.0124\n",
      " 0.0389\n",
      " 0.0363\n",
      " 0.0552\n",
      "-0.0424\n",
      " 0.0198\n",
      " 0.0216\n",
      " 0.0106\n",
      "-0.0244\n",
      "-0.0162\n",
      " 0.0442\n",
      "-0.0463\n",
      "-0.0659\n",
      "-0.0047\n",
      " 0.0221\n",
      "-0.0013\n",
      "-0.0242\n",
      "-0.0764\n",
      " 0.0648\n",
      "-0.0023\n",
      " 0.0199\n",
      " 0.0899\n",
      " 0.0615\n",
      "-0.0571\n",
      "-0.0746\n",
      "-0.0319\n",
      "-0.0264\n",
      " 0.0550\n",
      "-0.0031\n",
      "-0.0621\n",
      "-0.0838\n",
      "-0.0272\n",
      " 0.0791\n",
      " 0.0335\n",
      "-0.0875\n",
      "-0.0890\n",
      " 0.0987\n",
      " 0.0910\n",
      "-0.0132\n",
      "-0.0196\n",
      " 0.0773\n",
      " 0.0435\n",
      "-0.0189\n",
      " 0.0431\n",
      " 0.0500\n",
      " 0.0100\n",
      " 0.0674\n",
      " 0.0938\n",
      "-0.0190\n",
      " 0.0399\n",
      " 0.0377\n",
      "-0.0161\n",
      " 0.0594\n",
      " 0.0027\n",
      " 0.0193\n",
      "-0.0703\n",
      "-0.0280\n",
      " 0.0887\n",
      " 0.0909\n",
      " 0.0183\n",
      "[torch.FloatTensor of size 300]\n",
      "), AttrTensor(data=Variable containing:\n",
      " 4.1148e-02  1.4283e-01  1.0262e-01  ...   1.6913e-01 -4.6366e-04 -2.1437e-01\n",
      "-2.2190e-02  1.9403e-01  3.5221e-02  ...   1.7532e-01 -8.7326e-03 -2.1047e-01\n",
      " 5.7329e-02  2.1155e-01  4.5145e-02  ...   2.2593e-01 -8.2726e-03 -2.2440e-01\n",
      "                ...                   ⋱                   ...                \n",
      " 1.2566e-01  1.7495e-01 -4.3855e-03  ...   1.0610e-01  7.2281e-03 -2.6806e-01\n",
      " 2.1485e-01  2.3517e-01 -3.3907e-02  ...   1.1813e-02  6.8818e-02 -2.5869e-01\n",
      " 1.4875e-02  1.4525e-01  8.4670e-02  ...   1.2419e-01  4.8755e-02 -2.0207e-01\n",
      "[torch.FloatTensor of size 128x300]\n",
      ", lengths=\n",
      " 10\n",
      " 14\n",
      " 10\n",
      " 11\n",
      " 14\n",
      " 15\n",
      " 10\n",
      "  9\n",
      " 20\n",
      "  9\n",
      " 11\n",
      " 15\n",
      "  7\n",
      " 16\n",
      " 17\n",
      "  8\n",
      " 11\n",
      " 13\n",
      " 10\n",
      " 12\n",
      " 10\n",
      "  3\n",
      " 15\n",
      "  9\n",
      " 13\n",
      " 14\n",
      "  9\n",
      " 13\n",
      "  6\n",
      " 14\n",
      "  9\n",
      " 11\n",
      " 13\n",
      "  8\n",
      "  7\n",
      " 13\n",
      " 14\n",
      " 13\n",
      " 19\n",
      "  9\n",
      " 14\n",
      " 14\n",
      " 13\n",
      " 17\n",
      " 19\n",
      " 12\n",
      " 12\n",
      " 13\n",
      " 11\n",
      "  9\n",
      " 14\n",
      "  6\n",
      " 15\n",
      " 13\n",
      "  8\n",
      " 11\n",
      " 11\n",
      " 10\n",
      "  8\n",
      " 21\n",
      " 14\n",
      " 10\n",
      " 14\n",
      " 12\n",
      " 14\n",
      "  8\n",
      " 15\n",
      " 20\n",
      "  8\n",
      " 19\n",
      " 15\n",
      "  9\n",
      "  7\n",
      " 15\n",
      "  4\n",
      " 11\n",
      " 10\n",
      " 15\n",
      " 11\n",
      " 13\n",
      " 13\n",
      " 11\n",
      " 12\n",
      " 15\n",
      " 14\n",
      " 11\n",
      "  7\n",
      " 14\n",
      " 19\n",
      " 16\n",
      " 12\n",
      " 22\n",
      "  6\n",
      "  9\n",
      "  9\n",
      "  8\n",
      " 13\n",
      " 11\n",
      "  9\n",
      " 18\n",
      "  7\n",
      " 12\n",
      "  6\n",
      " 14\n",
      " 14\n",
      " 10\n",
      "  8\n",
      " 10\n",
      " 15\n",
      " 19\n",
      " 18\n",
      " 22\n",
      " 15\n",
      " 16\n",
      " 13\n",
      " 11\n",
      " 10\n",
      "  8\n",
      "  9\n",
      "  9\n",
      " 10\n",
      " 10\n",
      " 14\n",
      " 18\n",
      "  9\n",
      " 13\n",
      " 13\n",
      "  9\n",
      "[torch.LongTensor of size 128]\n",
      ", word_probs=\n",
      " 0.0312  0.0001  0.0005  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0033  0.0003  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0001  0.0053  ...   0.6172  0.6172  0.6172\n",
      "          ...             ⋱             ...          \n",
      " 0.0312  0.0002  0.0026  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0005  0.0010  ...   0.6172  0.6172  0.6172\n",
      " 0.0312  0.0007  0.0004  ...   0.6172  0.6172  0.6172\n",
      "[torch.FloatTensor of size 128x22]\n",
      ", pc=\n",
      "-0.0293\n",
      "-0.0238\n",
      "-0.0300\n",
      " 0.0457\n",
      "-0.0648\n",
      "-0.0081\n",
      " 0.0131\n",
      "-0.0109\n",
      " 0.0323\n",
      " 0.0220\n",
      " 0.0419\n",
      " 0.0286\n",
      "-0.0330\n",
      "-0.0504\n",
      " 0.0224\n",
      "-0.0672\n",
      "-0.0146\n",
      " 0.0135\n",
      "-0.0188\n",
      " 0.0931\n",
      "-0.0591\n",
      " 0.0672\n",
      "-0.0529\n",
      "-0.0544\n",
      "-0.0187\n",
      "-0.0325\n",
      "-0.0136\n",
      " 0.0032\n",
      " 0.0258\n",
      " 0.0538\n",
      "-0.0311\n",
      " 0.1236\n",
      "-0.0623\n",
      " 0.0431\n",
      " 0.0185\n",
      "-0.0313\n",
      " 0.0278\n",
      "-0.0490\n",
      " 0.0151\n",
      "-0.0598\n",
      " 0.0259\n",
      "-0.0009\n",
      "-0.0189\n",
      " 0.0682\n",
      " 0.0154\n",
      " 0.0038\n",
      " 0.0016\n",
      "-0.0049\n",
      "-0.0195\n",
      " 0.0006\n",
      " 0.0477\n",
      "-0.0645\n",
      " 0.0178\n",
      "-0.0052\n",
      " 0.0047\n",
      " 0.0620\n",
      " 0.0517\n",
      " 0.0265\n",
      "-0.0031\n",
      " 0.0951\n",
      " 0.0418\n",
      " 0.0178\n",
      " 0.1043\n",
      "-0.0060\n",
      "-0.0589\n",
      "-0.0161\n",
      "-0.0036\n",
      " 0.0471\n",
      "-0.0402\n",
      "-0.0009\n",
      " 0.0162\n",
      "-0.0032\n",
      " 0.0781\n",
      "-0.0482\n",
      "-0.0409\n",
      " 0.0630\n",
      " 0.1015\n",
      " 0.0019\n",
      "-0.0332\n",
      " 0.0060\n",
      " 0.0332\n",
      "-0.0096\n",
      "-0.0116\n",
      " 0.0436\n",
      "-0.0089\n",
      "-0.0359\n",
      "-0.0392\n",
      "-0.0064\n",
      " 0.0452\n",
      " 0.0251\n",
      " 0.0186\n",
      "-0.0402\n",
      " 0.0813\n",
      "-0.0337\n",
      " 0.0600\n",
      " 0.0500\n",
      " 0.0038\n",
      "-0.0028\n",
      "-0.0266\n",
      "-0.0355\n",
      " 0.0393\n",
      "-0.0479\n",
      " 0.0524\n",
      "-0.0127\n",
      "-0.0354\n",
      "-0.0375\n",
      "-0.0772\n",
      " 0.0341\n",
      " 0.0501\n",
      "-0.0347\n",
      " 0.0097\n",
      "-0.0048\n",
      "-0.0249\n",
      "-0.0396\n",
      "-0.0462\n",
      "-0.0467\n",
      " 0.0780\n",
      " 0.0190\n",
      "-0.0662\n",
      " 0.0707\n",
      " 0.1265\n",
      " 0.0105\n",
      "-0.0076\n",
      " 0.1652\n",
      " 0.0095\n",
      "-0.0004\n",
      " 0.0085\n",
      " 0.0581\n",
      " 0.0479\n",
      " 0.0695\n",
      "-0.0174\n",
      " 0.0723\n",
      "-0.0321\n",
      " 0.0770\n",
      " 0.0450\n",
      "-0.0101\n",
      "-0.0465\n",
      "-0.0048\n",
      " 0.0126\n",
      " 0.0771\n",
      " 0.0263\n",
      " 0.0770\n",
      " 0.0781\n",
      " 0.0143\n",
      "-0.0391\n",
      " 0.0952\n",
      "-0.0082\n",
      "-0.0490\n",
      "-0.0114\n",
      " 0.0072\n",
      " 0.1072\n",
      "-0.0806\n",
      "-0.0495\n",
      "-0.0714\n",
      "-0.0404\n",
      " 0.0043\n",
      "-0.0167\n",
      "-0.0521\n",
      " 0.0570\n",
      " 0.0205\n",
      " 0.0642\n",
      " 0.0612\n",
      "-0.0909\n",
      " 0.0273\n",
      " 0.0617\n",
      " 0.0290\n",
      "-0.0418\n",
      "-0.0492\n",
      " 0.1320\n",
      " 0.0569\n",
      "-0.0812\n",
      "-0.0963\n",
      "-0.1514\n",
      "-0.0287\n",
      "-0.0308\n",
      " 0.1220\n",
      "-0.0565\n",
      " 0.0192\n",
      "-0.0239\n",
      "-0.0805\n",
      " 0.0497\n",
      "-0.0723\n",
      " 0.0430\n",
      " 0.0444\n",
      "-0.0664\n",
      " 0.1304\n",
      " 0.0146\n",
      "-0.0835\n",
      " 0.1019\n",
      "-0.0104\n",
      "-0.0315\n",
      "-0.1260\n",
      " 0.0560\n",
      " 0.1042\n",
      "-0.1290\n",
      "-0.0128\n",
      "-0.0268\n",
      " 0.0263\n",
      "-0.1687\n",
      "-0.0807\n",
      " 0.0819\n",
      " 0.0281\n",
      " 0.0675\n",
      "-0.0231\n",
      " 0.0099\n",
      "-0.1055\n",
      "-0.1087\n",
      "-0.0130\n",
      " 0.1551\n",
      " 0.0006\n",
      " 0.2553\n",
      "-0.0152\n",
      "-0.0274\n",
      "-0.1316\n",
      " 0.0048\n",
      "-0.0476\n",
      "-0.0320\n",
      "-0.1416\n",
      "-0.0778\n",
      " 0.0291\n",
      "-0.0572\n",
      "-0.0832\n",
      "-0.0571\n",
      " 0.0819\n",
      "-0.0042\n",
      " 0.0155\n",
      "-0.0676\n",
      "-0.0856\n",
      " 0.0197\n",
      " 0.0345\n",
      " 0.0790\n",
      " 0.0627\n",
      "-0.0077\n",
      "-0.0260\n",
      "-0.0069\n",
      " 0.0138\n",
      " 0.0037\n",
      " 0.0419\n",
      "-0.0663\n",
      "-0.0455\n",
      "-0.0091\n",
      " 0.0334\n",
      " 0.0302\n",
      " 0.0615\n",
      "-0.0337\n",
      " 0.0144\n",
      " 0.0276\n",
      " 0.0037\n",
      "-0.0270\n",
      "-0.0214\n",
      " 0.0380\n",
      "-0.0490\n",
      "-0.0610\n",
      "-0.0114\n",
      " 0.0212\n",
      "-0.0043\n",
      "-0.0252\n",
      "-0.0794\n",
      " 0.0694\n",
      "-0.0018\n",
      " 0.0163\n",
      " 0.0890\n",
      " 0.0528\n",
      "-0.0654\n",
      "-0.0761\n",
      "-0.0409\n",
      "-0.0324\n",
      " 0.0528\n",
      " 0.0056\n",
      "-0.0602\n",
      "-0.0799\n",
      "-0.0274\n",
      " 0.0790\n",
      " 0.0300\n",
      "-0.0781\n",
      "-0.0925\n",
      " 0.0997\n",
      " 0.0885\n",
      "-0.0069\n",
      "-0.0220\n",
      " 0.0879\n",
      " 0.0321\n",
      "-0.0182\n",
      " 0.0468\n",
      " 0.0564\n",
      " 0.0137\n",
      " 0.0656\n",
      " 0.0846\n",
      "-0.0195\n",
      " 0.0395\n",
      " 0.0375\n",
      "-0.0157\n",
      " 0.0535\n",
      " 0.0050\n",
      " 0.0189\n",
      "-0.0691\n",
      "-0.0334\n",
      " 0.0911\n",
      " 0.0988\n",
      " 0.0137\n",
      "[torch.FloatTensor of size 300]\n",
      "))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Variable data has to be a tensor, but got Variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-f64be09cb618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.6/site-packages/deepmatcher/models/core.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             left_summary, right_summary = self.attr_summarizers[name](embeddings[left],\n\u001b[0;32m--> 427\u001b[0;31m                                                                       embeddings[right])\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;31m# Remove metadata information at this point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/testenv/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 raise RuntimeError(\n",
      "\u001b[0;32m<ipython-input-22-a8e35e543933>\u001b[0m in \u001b[0;36m_return_input\u001b[0;34m(module, module_input, module_output)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_return_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodule_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodule_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0mcurrent_layer_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcurrent_layer_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Variable data has to be a tensor, but got Variable"
     ]
    }
   ],
   "source": [
    "dataset = dm.data.process(path='../Structured/itunes-amazon',train='negatives.csv',\n",
    "                          left_prefix='ltable_',right_prefix='rtable_',cache='negatives.pth')\n",
    "dataset_tuple = dataset,\n",
    "splits = MatchingIterator.splits(dataset_tuple,batch_size=128, device = -1)\n",
    "tupleids = []\n",
    "layer_inputs = []\n",
    "hook = hybrid_model.attr_summarizers.Song_Name.register_forward_hook(print)\n",
    "batches = []\n",
    "for batch in splits[0]:\n",
    "    batches.append(batch)\n",
    "hybrid_model.forward(batches[0])\n",
    "hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
