{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 13\n",
    "We want to evaluate Ri computation with constant attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create altered dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepmatcher as dm\n",
    "import pandas as pd\n",
    "import torch\n",
    "from utilities_functions.intermediate_layer_extraction import return_layer_input_output\n",
    "from utilities_functions.ri_calculator import find_smallest_variation_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../Structured/itunes-amazon/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ltable_Price'] = \"Ignore\"\n",
    "train_df['rtable_Price'] = \"Ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘temp’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('temp/train_constantprice.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model and calculate Ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,validation,test = dm.data.process('temp',train='train_constantprice.csv',\n",
    "                                        validation='validation.csv',\n",
    "                                       test='test.csv',left_prefix='ltable_',right_prefix='rtable_',cache='exp13.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (attr_summarizers): ModuleMap(\n",
       "    (Song_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Genre): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Price): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Time): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Released): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_summarizer): Hybrid(\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge(\n",
       "    )\n",
       "    (Artist_Name): Merge(\n",
       "    )\n",
       "    (Album_Name): Merge(\n",
       "    )\n",
       "    (Genre): Merge(\n",
       "    )\n",
       "    (Price): Merge(\n",
       "    )\n",
       "    (CopyRight): Merge(\n",
       "    )\n",
       "    (Time): Merge(\n",
       "    )\n",
       "    (Released): Merge(\n",
       "    )\n",
       "  )\n",
       "  (attr_comparator): Merge(\n",
       "  )\n",
       "  (attr_merge): Merge(\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax()\n",
       "  )\n",
       "  (embed): ModuleMap(\n",
       "    (ltable_Song_Name): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_Album_Name): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_Genre): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_Price): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_CopyRight): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_Time): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (ltable_Released): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Song_Name): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Album_Name): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Genre): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Price): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_CopyRight): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Time): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "    (rtable_Released): NoMeta(\n",
       "      (module): Embedding(2228, 300)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "#hybrid_model.run_train(train,validation,best_save_path='../../models/itunesamazon_hybrid_constantprice.pth',pos_neg_ratio=4,epochs=20,batch_size=16)\n",
    "hybrid_model.load_state('../../models/itunesamazon_hybrid_constantprice.pth')\n",
    "hybrid_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  EVAL Epoch 4\n",
      "Finished Epoch 4 || Run Time:    0.7 | Load Time:    0.4 || F1:  91.53 | Prec:  96.43 | Rec:  87.10 || Ex/s:  97.66\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.52542372881356"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model.run_eval(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Ri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_classifier_inputs,neg_classifier_outputs,neg_ids = return_layer_input_output('../../Structured/itunes-amazon/'\n",
    "                                                                         ,'negatives',32,hybrid_model,\n",
    "                                                                        hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_classifier_inputs,pos_classifier_outputs,pos_ids = return_layer_input_output('../../Structured/itunes-amazon',\n",
    "                                                                       'positives',32,hybrid_model,\n",
    "                                                                       hybrid_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_classifier_inputs = list(map(lambda x: x[0],neg_classifier_inputs))\n",
    "positive_classifier_inputs = list(map(lambda x: x[0],pos_classifier_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 0\n",
      "Processing sample 1\n",
      "Processing sample 2\n",
      "Processing sample 3\n",
      "Processing sample 4\n",
      "Processing sample 5\n",
      "Processing sample 6\n",
      "Processing sample 7\n",
      "Processing sample 8\n",
      "Processing sample 9\n",
      "Processing sample 10\n",
      "Processing sample 11\n",
      "Processing sample 12\n",
      "Processing sample 13\n",
      "Processing sample 14\n",
      "Processing sample 15\n",
      "Processing sample 16\n",
      "Processing sample 17\n",
      "Processing sample 18\n",
      "Processing sample 19\n",
      "Processing sample 20\n",
      "Processing sample 21\n",
      "Processing sample 22\n",
      "Processing sample 23\n",
      "Processing sample 24\n",
      "Processing sample 25\n",
      "Processing sample 26\n",
      "Processing sample 27\n",
      "Processing sample 28\n",
      "Processing sample 29\n",
      "Processing sample 30\n",
      "Processing sample 31\n",
      "Processing sample 32\n",
      "Processing sample 33\n",
      "Processing sample 34\n",
      "Processing sample 35\n",
      "Processing sample 36\n",
      "Processing sample 37\n",
      "Processing sample 38\n",
      "Processing sample 39\n",
      "Processing sample 40\n",
      "Processing sample 41\n",
      "Processing sample 42\n",
      "Processing sample 43\n",
      "Processing sample 44\n",
      "Processing sample 45\n",
      "Processing sample 46\n",
      "Processing sample 47\n",
      "Processing sample 48\n",
      "Processing sample 49\n",
      "Processing sample 50\n",
      "Processing sample 51\n",
      "Processing sample 52\n",
      "Processing sample 53\n",
      "Processing sample 54\n",
      "Processing sample 55\n",
      "Processing sample 56\n",
      "Processing sample 57\n",
      "Processing sample 58\n",
      "Processing sample 59\n",
      "Processing sample 60\n",
      "Processing sample 61\n",
      "Processing sample 62\n",
      "Processing sample 63\n",
      "Processing sample 64\n",
      "Processing sample 65\n",
      "Processing sample 66\n",
      "Processing sample 67\n",
      "Processing sample 68\n",
      "Processing sample 69\n",
      "Processing sample 70\n",
      "Processing sample 71\n",
      "Processing sample 72\n",
      "Processing sample 73\n",
      "Processing sample 74\n",
      "Processing sample 75\n",
      "Processing sample 76\n",
      "Processing sample 77\n",
      "Processing sample 78\n",
      "Processing sample 79\n",
      "Processing sample 80\n",
      "Processing sample 81\n",
      "Processing sample 82\n",
      "Processing sample 83\n",
      "Processing sample 84\n",
      "Processing sample 85\n",
      "Processing sample 86\n",
      "Processing sample 87\n",
      "Processing sample 88\n",
      "Processing sample 89\n",
      "Processing sample 90\n",
      "Processing sample 91\n",
      "Processing sample 92\n",
      "Processing sample 93\n",
      "Processing sample 94\n",
      "Processing sample 95\n",
      "Processing sample 96\n",
      "Processing sample 97\n",
      "Processing sample 98\n",
      "Processing sample 99\n",
      "Processing sample 100\n",
      "Processing sample 101\n",
      "Processing sample 102\n",
      "Processing sample 103\n",
      "Processing sample 104\n",
      "Processing sample 105\n",
      "Processing sample 106\n",
      "Processing sample 107\n",
      "Processing sample 108\n",
      "Processing sample 109\n",
      "Processing sample 110\n",
      "Processing sample 111\n",
      "Processing sample 112\n",
      "Processing sample 113\n",
      "Processing sample 114\n",
      "Processing sample 115\n",
      "Processing sample 116\n",
      "Processing sample 117\n",
      "Processing sample 118\n",
      "Processing sample 119\n",
      "Processing sample 120\n",
      "Processing sample 121\n",
      "Processing sample 122\n",
      "Processing sample 123\n",
      "Processing sample 124\n",
      "Processing sample 125\n",
      "Processing sample 126\n",
      "Processing sample 127\n",
      "Processing sample 128\n",
      "Processing sample 129\n",
      "Processing sample 130\n",
      "Processing sample 131\n",
      "Processing sample 132\n",
      "Processing sample 133\n",
      "Processing sample 134\n",
      "Processing sample 135\n",
      "Processing sample 136\n",
      "Processing sample 137\n",
      "Processing sample 138\n",
      "Processing sample 139\n",
      "Processing sample 140\n",
      "Processing sample 141\n",
      "Processing sample 142\n",
      "Processing sample 143\n",
      "Processing sample 144\n",
      "Processing sample 145\n",
      "Processing sample 146\n",
      "Processing sample 147\n",
      "Processing sample 148\n",
      "Processing sample 149\n",
      "Processing sample 150\n",
      "Processing sample 151\n",
      "Processing sample 152\n",
      "Processing sample 153\n",
      "Processing sample 154\n",
      "Processing sample 155\n",
      "Processing sample 156\n",
      "Processing sample 157\n",
      "Processing sample 158\n",
      "Processing sample 159\n",
      "Processing sample 160\n",
      "Processing sample 161\n",
      "Processing sample 162\n",
      "Processing sample 163\n",
      "Processing sample 164\n",
      "Processing sample 165\n",
      "Processing sample 166\n",
      "Processing sample 167\n",
      "Processing sample 168\n",
      "Processing sample 169\n",
      "Processing sample 170\n",
      "Processing sample 171\n",
      "Processing sample 172\n",
      "Processing sample 173\n",
      "Processing sample 174\n",
      "Processing sample 175\n",
      "Processing sample 176\n",
      "Processing sample 177\n",
      "Processing sample 178\n",
      "Processing sample 179\n",
      "Processing sample 180\n",
      "Processing sample 181\n",
      "Processing sample 182\n",
      "Processing sample 183\n",
      "Processing sample 184\n",
      "Processing sample 185\n",
      "Processing sample 186\n",
      "Processing sample 187\n",
      "Processing sample 188\n",
      "Processing sample 189\n",
      "Processing sample 190\n",
      "Processing sample 191\n",
      "Processing sample 192\n",
      "Processing sample 193\n",
      "Processing sample 194\n",
      "Processing sample 195\n",
      "Processing sample 196\n",
      "Processing sample 197\n",
      "Processing sample 198\n",
      "Processing sample 199\n",
      "Processing sample 200\n",
      "Processing sample 201\n",
      "Processing sample 202\n",
      "Processing sample 203\n",
      "Processing sample 204\n",
      "Processing sample 205\n",
      "Processing sample 206\n",
      "Processing sample 207\n",
      "Processing sample 208\n",
      "Processing sample 209\n",
      "Processing sample 210\n",
      "Processing sample 211\n",
      "Processing sample 212\n",
      "Processing sample 213\n",
      "Processing sample 214\n",
      "Processing sample 215\n",
      "Processing sample 216\n",
      "Processing sample 217\n",
      "Processing sample 218\n",
      "Processing sample 219\n",
      "Processing sample 220\n",
      "Processing sample 221\n",
      "Processing sample 222\n",
      "Processing sample 223\n",
      "Processing sample 224\n",
      "Processing sample 225\n",
      "Processing sample 226\n",
      "Processing sample 227\n",
      "Processing sample 228\n",
      "Processing sample 229\n",
      "Processing sample 230\n",
      "Processing sample 231\n",
      "Processing sample 232\n",
      "Processing sample 233\n",
      "Processing sample 234\n",
      "Processing sample 235\n",
      "Processing sample 236\n",
      "Processing sample 237\n",
      "Processing sample 238\n",
      "Processing sample 239\n",
      "Processing sample 240\n",
      "Processing sample 241\n",
      "Processing sample 242\n",
      "Processing sample 243\n",
      "Processing sample 244\n",
      "Processing sample 245\n",
      "Processing sample 246\n",
      "Processing sample 247\n",
      "Processing sample 248\n",
      "Processing sample 249\n",
      "Processing sample 250\n",
      "Processing sample 251\n",
      "Processing sample 252\n",
      "Processing sample 253\n",
      "Processing sample 254\n",
      "Processing sample 255\n",
      "Processing sample 256\n",
      "Processing sample 257\n",
      "Processing sample 258\n",
      "Processing sample 259\n",
      "Processing sample 260\n",
      "Processing sample 261\n",
      "Processing sample 262\n",
      "Processing sample 263\n",
      "Processing sample 264\n",
      "Processing sample 265\n",
      "Processing sample 266\n",
      "Processing sample 267\n",
      "Processing sample 268\n",
      "Processing sample 269\n",
      "Processing sample 270\n",
      "Processing sample 271\n",
      "Processing sample 272\n",
      "Processing sample 273\n",
      "Processing sample 274\n",
      "Processing sample 275\n",
      "Processing sample 276\n",
      "Processing sample 277\n",
      "Processing sample 278\n",
      "Processing sample 279\n",
      "Processing sample 280\n",
      "Processing sample 281\n",
      "Processing sample 282\n",
      "Processing sample 283\n",
      "Processing sample 284\n",
      "Processing sample 285\n",
      "Processing sample 286\n",
      "Processing sample 287\n",
      "Processing sample 288\n",
      "Processing sample 289\n",
      "Processing sample 290\n",
      "Processing sample 291\n",
      "Processing sample 292\n",
      "Processing sample 293\n",
      "Processing sample 294\n",
      "Processing sample 295\n",
      "Processing sample 296\n",
      "Processing sample 297\n",
      "Processing sample 298\n",
      "Processing sample 299\n",
      "Processing sample 300\n",
      "Processing sample 301\n",
      "Processing sample 302\n",
      "Processing sample 303\n",
      "Processing sample 304\n",
      "Processing sample 305\n",
      "Processing sample 306\n",
      "Processing sample 307\n",
      "Processing sample 308\n",
      "Processing sample 309\n",
      "Processing sample 310\n",
      "Processing sample 311\n",
      "Processing sample 312\n",
      "Processing sample 313\n",
      "Processing sample 314\n",
      "Processing sample 315\n",
      "Processing sample 316\n",
      "Processing sample 317\n",
      "Processing sample 318\n",
      "Processing sample 319\n",
      "Processing sample 320\n",
      "Processing sample 321\n",
      "Processing sample 322\n",
      "Processing sample 323\n",
      "Processing sample 324\n",
      "Processing sample 325\n",
      "Processing sample 326\n",
      "Processing sample 327\n",
      "Processing sample 328\n",
      "Processing sample 329\n",
      "Processing sample 330\n",
      "Processing sample 331\n",
      "Processing sample 332\n",
      "Processing sample 333\n",
      "Processing sample 334\n",
      "Processing sample 335\n",
      "Processing sample 336\n",
      "Processing sample 337\n",
      "Processing sample 338\n",
      "Processing sample 339\n",
      "Processing sample 340\n",
      "Processing sample 341\n",
      "Processing sample 342\n",
      "Processing sample 343\n",
      "Processing sample 344\n",
      "Processing sample 345\n",
      "Processing sample 346\n",
      "Processing sample 347\n",
      "Processing sample 348\n",
      "Processing sample 349\n",
      "Processing sample 350\n",
      "Processing sample 351\n",
      "Processing sample 352\n",
      "Processing sample 353\n",
      "Processing sample 354\n",
      "Processing sample 355\n",
      "Processing sample 356\n",
      "Processing sample 357\n",
      "Processing sample 358\n",
      "Processing sample 359\n",
      "Processing sample 360\n",
      "Processing sample 361\n",
      "Processing sample 362\n",
      "Processing sample 363\n",
      "Processing sample 364\n",
      "Processing sample 365\n",
      "Processing sample 366\n",
      "Processing sample 367\n",
      "Processing sample 368\n",
      "Processing sample 369\n",
      "Processing sample 370\n",
      "Processing sample 371\n",
      "Processing sample 372\n",
      "Processing sample 373\n",
      "Processing sample 374\n",
      "Processing sample 375\n",
      "Processing sample 376\n",
      "Processing sample 377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 378\n",
      "Processing sample 379\n",
      "Processing sample 380\n",
      "Processing sample 381\n",
      "Processing sample 382\n",
      "Processing sample 383\n",
      "Processing sample 384\n",
      "Processing sample 385\n",
      "Processing sample 386\n",
      "Processing sample 387\n",
      "Processing sample 388\n",
      "Processing sample 389\n",
      "Processing sample 390\n",
      "Processing sample 391\n",
      "Processing sample 392\n",
      "Processing sample 393\n",
      "Processing sample 394\n",
      "Processing sample 395\n",
      "Processing sample 396\n",
      "Processing sample 397\n",
      "Processing sample 398\n",
      "Processing sample 399\n",
      "Processing sample 400\n",
      "Processing sample 401\n",
      "Processing sample 402\n",
      "Processing sample 403\n",
      "Processing sample 404\n",
      "Processing sample 405\n",
      "Processing sample 406\n"
     ]
    }
   ],
   "source": [
    "current_sample = 0\n",
    "#each column of this matrix is related to a specific attribute\n",
    "negatives_ri = []\n",
    "for batch in negative_classifier_inputs:\n",
    "    for sample_index in range(len(batch)):\n",
    "        print('Processing sample {}'.format(current_sample))\n",
    "        current_sample_ri = current_sample_ris = find_smallest_variation_to_change(hybrid_model.classifier,\n",
    "                                                                                    classifier_length=1200,\n",
    "                                                                                    attribute_length=150,\n",
    "                                                                                    input_matrix=batch,\n",
    "                                                                                    vector_index=sample_index,\n",
    "                                                                                    attributes=[4],class_to_reach=1)\n",
    "        negatives_ri.append(current_sample_ri)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.749774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.312891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.273142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.270634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.923174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.796748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.624544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.082141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.842767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.472125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Price\n",
       "0   3.749774\n",
       "1   8.312891\n",
       "2   8.273142\n",
       "3   8.270634\n",
       "4   7.923174\n",
       "5   7.796748\n",
       "6   8.624544\n",
       "7  13.082141\n",
       "8   7.842767\n",
       "9   8.472125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri_norms_negative_samples = []\n",
    "for ri in negatives_ri:\n",
    "    ri_norms_negative_samples.append(torch.norm(ri).data[0])\n",
    "neg_variation_df = pd.DataFrame(data = ri_norms_negative_samples,columns = ['Price'])\n",
    "neg_variation_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.9653386295090034, pvalue=0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "kstest(neg_variation_df['Price'],'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 0\n",
      "Processing sample 1\n",
      "Processing sample 2\n",
      "Processing sample 3\n",
      "Processing sample 4\n",
      "Processing sample 5\n",
      "Processing sample 6\n",
      "Processing sample 7\n",
      "Processing sample 8\n",
      "Processing sample 9\n",
      "Processing sample 10\n",
      "Processing sample 11\n",
      "Processing sample 12\n",
      "Processing sample 13\n",
      "Processing sample 14\n",
      "Processing sample 15\n",
      "Processing sample 16\n",
      "Processing sample 17\n",
      "Processing sample 18\n",
      "Processing sample 19\n",
      "Processing sample 20\n",
      "Processing sample 21\n",
      "Processing sample 22\n",
      "Processing sample 23\n",
      "Processing sample 24\n",
      "Processing sample 25\n",
      "Processing sample 26\n",
      "Processing sample 27\n",
      "Processing sample 28\n",
      "Processing sample 29\n",
      "Processing sample 30\n",
      "Processing sample 31\n",
      "Processing sample 32\n",
      "Processing sample 33\n",
      "Processing sample 34\n",
      "Processing sample 35\n",
      "Processing sample 36\n",
      "Processing sample 37\n",
      "Processing sample 38\n",
      "Processing sample 39\n",
      "Processing sample 40\n",
      "Processing sample 41\n",
      "Processing sample 42\n",
      "Processing sample 43\n",
      "Processing sample 44\n",
      "Processing sample 45\n",
      "Processing sample 46\n",
      "Processing sample 47\n",
      "Processing sample 48\n",
      "Processing sample 49\n",
      "Processing sample 50\n",
      "Processing sample 51\n",
      "Processing sample 52\n",
      "Processing sample 53\n",
      "Processing sample 54\n",
      "Processing sample 55\n",
      "Processing sample 56\n",
      "Processing sample 57\n",
      "Processing sample 58\n",
      "Processing sample 59\n",
      "Processing sample 60\n",
      "Processing sample 61\n",
      "Processing sample 62\n",
      "Processing sample 63\n",
      "Processing sample 64\n",
      "Processing sample 65\n",
      "Processing sample 66\n",
      "Processing sample 67\n",
      "Processing sample 68\n",
      "Processing sample 69\n",
      "Processing sample 70\n",
      "Processing sample 71\n",
      "Processing sample 72\n",
      "Processing sample 73\n",
      "Processing sample 74\n",
      "Processing sample 75\n",
      "Processing sample 76\n",
      "Processing sample 77\n",
      "Processing sample 78\n",
      "Processing sample 79\n",
      "Processing sample 80\n",
      "Processing sample 81\n",
      "Processing sample 82\n",
      "Processing sample 83\n",
      "Processing sample 84\n",
      "Processing sample 85\n",
      "Processing sample 86\n",
      "Processing sample 87\n",
      "Processing sample 88\n",
      "Processing sample 89\n",
      "Processing sample 90\n",
      "Processing sample 91\n",
      "Processing sample 92\n",
      "Processing sample 93\n",
      "Processing sample 94\n",
      "Processing sample 95\n",
      "Processing sample 96\n",
      "Processing sample 97\n",
      "Processing sample 98\n",
      "Processing sample 99\n",
      "Processing sample 100\n",
      "Processing sample 101\n",
      "Processing sample 102\n",
      "Processing sample 103\n",
      "Processing sample 104\n",
      "Processing sample 105\n",
      "Processing sample 106\n",
      "Processing sample 107\n",
      "Processing sample 108\n",
      "Processing sample 109\n",
      "Processing sample 110\n",
      "Processing sample 111\n",
      "Processing sample 112\n",
      "Processing sample 113\n",
      "Processing sample 114\n",
      "Processing sample 115\n",
      "Processing sample 116\n",
      "Processing sample 117\n",
      "Processing sample 118\n",
      "Processing sample 119\n",
      "Processing sample 120\n",
      "Processing sample 121\n",
      "Processing sample 122\n",
      "Processing sample 123\n",
      "Processing sample 124\n",
      "Processing sample 125\n",
      "Processing sample 126\n",
      "Processing sample 127\n",
      "Processing sample 128\n",
      "Processing sample 129\n",
      "Processing sample 130\n",
      "Processing sample 131\n"
     ]
    }
   ],
   "source": [
    "current_sample = 0\n",
    "#each column of this matrix is related to a specific attribute\n",
    "positives_ri = []\n",
    "for batch in positive_classifier_inputs:\n",
    "    for sample_index in range(len(batch)):\n",
    "        print('Processing sample {}'.format(current_sample))\n",
    "        current_sample_ri = current_sample_ris = find_smallest_variation_to_change(hybrid_model.classifier,\n",
    "                                                                                    classifier_length=1200,\n",
    "                                                                                    attribute_length=150,\n",
    "                                                                                    input_matrix=batch,\n",
    "                                                                                    vector_index=sample_index,\n",
    "                                                                                    attributes=[4]\n",
    "                                                                                    ,class_to_reach=0)\n",
    "        positives_ri.append(current_sample_ri)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>15.567692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>13.085272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2.820915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2.657700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>7.753742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>12.946536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>10.072795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.607734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.696025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Price\n",
       "122   0.000000\n",
       "123  15.567692\n",
       "124  13.085272\n",
       "125   2.820915\n",
       "126   2.657700\n",
       "127   7.753742\n",
       "128  12.946536\n",
       "129  10.072795\n",
       "130   7.607734\n",
       "131   7.696025"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri_norms_positive_samples = []\n",
    "for ri in positives_ri:\n",
    "    ri_norms_positive_samples.append(torch.norm(ri).data[0])\n",
    "variation_pos_df = pd.DataFrame(data =ri_norms_positive_samples,columns = ['Price'])\n",
    "variation_pos_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gen-Son</th>\n",
       "      <th>Gen-Art</th>\n",
       "      <th>Gen-Alb</th>\n",
       "      <th>Gen-Pri</th>\n",
       "      <th>Gen-Cop</th>\n",
       "      <th>Gen-Tim</th>\n",
       "      <th>Gen-Rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.400168</td>\n",
       "      <td>3.271580</td>\n",
       "      <td>2.831830</td>\n",
       "      <td>2.292891</td>\n",
       "      <td>3.141664</td>\n",
       "      <td>1.739190</td>\n",
       "      <td>3.580072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.743701</td>\n",
       "      <td>4.987300</td>\n",
       "      <td>4.367309</td>\n",
       "      <td>3.683948</td>\n",
       "      <td>4.715356</td>\n",
       "      <td>1.911734</td>\n",
       "      <td>5.328947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.877554</td>\n",
       "      <td>5.257379</td>\n",
       "      <td>4.511127</td>\n",
       "      <td>3.632184</td>\n",
       "      <td>5.149188</td>\n",
       "      <td>2.776563</td>\n",
       "      <td>5.678788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.821429</td>\n",
       "      <td>9.472612</td>\n",
       "      <td>7.955276</td>\n",
       "      <td>6.443750</td>\n",
       "      <td>9.441951</td>\n",
       "      <td>4.030622</td>\n",
       "      <td>10.085423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.139969</td>\n",
       "      <td>10.196482</td>\n",
       "      <td>8.417581</td>\n",
       "      <td>6.537127</td>\n",
       "      <td>10.758584</td>\n",
       "      <td>4.926408</td>\n",
       "      <td>11.112793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gen-Son    Gen-Art   Gen-Alb   Gen-Pri    Gen-Cop   Gen-Tim    Gen-Rel\n",
       "0  2.400168   3.271580  2.831830  2.292891   3.141664  1.739190   3.580072\n",
       "1  3.743701   4.987300  4.367309  3.683948   4.715356  1.911734   5.328947\n",
       "2  3.877554   5.257379  4.511127  3.632184   5.149188  2.776563   5.678788\n",
       "3  6.821429   9.472612  7.955276  6.443750   9.441951  4.030622  10.085423\n",
       "4  7.139969  10.196482  8.417581  6.537127  10.758584  4.926408  11.112793"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kstest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4000537664659563\n",
      "4.634881623329655\n",
      "4.014316831865618\n",
      "3.23825285127086\n",
      "4.565991144026479\n",
      "2.4156884031911052\n",
      "4.990320594080033\n"
     ]
    }
   ],
   "source": [
    "for col in list(variation_pos_df):\n",
    "    print(variation_pos_df[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_parse_args() missing 1 required positional argument: 's'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-676a64e218fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkstest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariation_pos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gen-Cop'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lognorm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nvidia/anaconda3/envs/testenv/lib/python3.6/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mkstest\u001b[0;34m(rvs, cdf, args, N, alternative, mode)\u001b[0m\n\u001b[1;32m   4400\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4401\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4402\u001b[0;31m     \u001b[0mcdfvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m     \u001b[0;31m# to not break compatibility with existing code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvidia/anaconda3/envs/testenv/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mcdf\u001b[0;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[1;32m   1739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m         \"\"\"\n\u001b[0;32m-> 1741\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _parse_args() missing 1 required positional argument: 's'"
     ]
    }
   ],
   "source": [
    "kstest(variation_pos_df['Gen-Cop'],'lognorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = variation_pos_df['Gen-Tim']\n",
    "fig = plt.figure()\n",
    "plt.hist(x, bins=10)\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel('Frequencies')\n",
    "#plt.show()\n",
    "fig.savefig('distance_values_negatives_standardencoding.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gen-Son</th>\n",
       "      <th>Gen-Art</th>\n",
       "      <th>Gen-Alb</th>\n",
       "      <th>Gen-Pri</th>\n",
       "      <th>Gen-Cop</th>\n",
       "      <th>Gen-Tim</th>\n",
       "      <th>Gen-Rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.400168</td>\n",
       "      <td>3.271580</td>\n",
       "      <td>2.831830</td>\n",
       "      <td>2.292891</td>\n",
       "      <td>3.141664</td>\n",
       "      <td>1.739190</td>\n",
       "      <td>3.580072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.743701</td>\n",
       "      <td>4.987300</td>\n",
       "      <td>4.367309</td>\n",
       "      <td>3.683948</td>\n",
       "      <td>4.715356</td>\n",
       "      <td>1.911734</td>\n",
       "      <td>5.328947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.877554</td>\n",
       "      <td>5.257379</td>\n",
       "      <td>4.511127</td>\n",
       "      <td>3.632184</td>\n",
       "      <td>5.149188</td>\n",
       "      <td>2.776563</td>\n",
       "      <td>5.678788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.821429</td>\n",
       "      <td>9.472612</td>\n",
       "      <td>7.955276</td>\n",
       "      <td>6.443750</td>\n",
       "      <td>9.441951</td>\n",
       "      <td>4.030622</td>\n",
       "      <td>10.085423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.139969</td>\n",
       "      <td>10.196482</td>\n",
       "      <td>8.417581</td>\n",
       "      <td>6.537127</td>\n",
       "      <td>10.758584</td>\n",
       "      <td>4.926408</td>\n",
       "      <td>11.112793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.628982</td>\n",
       "      <td>5.023585</td>\n",
       "      <td>4.316590</td>\n",
       "      <td>3.409490</td>\n",
       "      <td>4.951978</td>\n",
       "      <td>2.530789</td>\n",
       "      <td>5.579182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.900857</td>\n",
       "      <td>5.159257</td>\n",
       "      <td>4.488623</td>\n",
       "      <td>3.688363</td>\n",
       "      <td>4.902045</td>\n",
       "      <td>2.834462</td>\n",
       "      <td>5.512400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.447506</td>\n",
       "      <td>1.827793</td>\n",
       "      <td>1.628657</td>\n",
       "      <td>1.438763</td>\n",
       "      <td>1.694015</td>\n",
       "      <td>1.164686</td>\n",
       "      <td>1.908162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gen-Son    Gen-Art   Gen-Alb   Gen-Pri    Gen-Cop   Gen-Tim    Gen-Rel\n",
       "0  2.400168   3.271580  2.831830  2.292891   3.141664  1.739190   3.580072\n",
       "1  3.743701   4.987300  4.367309  3.683948   4.715356  1.911734   5.328947\n",
       "2  3.877554   5.257379  4.511127  3.632184   5.149188  2.776563   5.678788\n",
       "3  6.821429   9.472612  7.955276  6.443750   9.441951  4.030622  10.085423\n",
       "4  7.139969  10.196482  8.417581  6.537127  10.758584  4.926408  11.112793\n",
       "5  3.628982   5.023585  4.316590  3.409490   4.951978  2.530789   5.579182\n",
       "6  3.900857   5.159257  4.488623  3.688363   4.902045  2.834462   5.512400\n",
       "7  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   0.000000\n",
       "8  0.000000   0.000000  0.000000  0.000000   0.000000  0.000000   0.000000\n",
       "9  1.447506   1.827793  1.628657  1.438763   1.694015  1.164686   1.908162"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variation_pos_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
