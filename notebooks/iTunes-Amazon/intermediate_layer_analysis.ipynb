{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepmatcher as dm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "from utils import Hook,return_layer_input_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'sample_data/itunes-amazon'\n",
    "datasets = dm.data.process(data_dir, train='train.csv', validation='validation.csv',\n",
    "                           test='price-test.csv')\n",
    "train = datasets[0]\n",
    "validation = datasets[1]\n",
    "test = datasets[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>left_Song_Name</th>\n",
       "      <th>left_Artist_Name</th>\n",
       "      <th>left_Album_Name</th>\n",
       "      <th>left_Genre</th>\n",
       "      <th>left_Price</th>\n",
       "      <th>left_CopyRight</th>\n",
       "      <th>left_Time</th>\n",
       "      <th>left_Released</th>\n",
       "      <th>right_Song_Name</th>\n",
       "      <th>right_Artist_Name</th>\n",
       "      <th>right_Album_Name</th>\n",
       "      <th>right_Genre</th>\n",
       "      <th>right_Price</th>\n",
       "      <th>right_CopyRight</th>\n",
       "      <th>right_Time</th>\n",
       "      <th>right_Released</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "      <td>baby when the light ( david guetta &amp; fred rist...</td>\n",
       "      <td>david guetta</td>\n",
       "      <td>pop life ( extended version ) [ bonus version ]</td>\n",
       "      <td>dance , music , rock , pop , house , electroni...</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãñ 2007 gum records</td>\n",
       "      <td>6:17</td>\n",
       "      <td>18-sep-07</td>\n",
       "      <td>revolver ( madonna vs. david guetta feat . lil...</td>\n",
       "      <td>david guetta</td>\n",
       "      <td>one love ( deluxe version )</td>\n",
       "      <td>dance &amp; electronic</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( c ) 2014 swedish house mafia holdings ltd ( ...</td>\n",
       "      <td>3:18</td>\n",
       "      <td>august 21 , 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>outversion</td>\n",
       "      <td>mark ronson</td>\n",
       "      <td>version</td>\n",
       "      <td>pop , music , r &amp; b / soul , soul , dance , ro...</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>2007 mark ronson under exclusive license to so...</td>\n",
       "      <td>1:50</td>\n",
       "      <td>10-jul-07</td>\n",
       "      <td>outversion</td>\n",
       "      <td>mark ronson</td>\n",
       "      <td>version [ explicit ]</td>\n",
       "      <td>pop</td>\n",
       "      <td>$ 0.99</td>\n",
       "      <td>( c ) 2011 j'adore records</td>\n",
       "      <td>1:50</td>\n",
       "      <td>july 10 , 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "      <td>peer pressure ( feat . traci nelson )</td>\n",
       "      <td>snoop dogg</td>\n",
       "      <td>doggumentary</td>\n",
       "      <td>hip-hop/rap , music , rock , gangsta rap , wes...</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãñ 2011 capitol records , llc . all rights r...</td>\n",
       "      <td>4:07</td>\n",
       "      <td>29-mar-11</td>\n",
       "      <td>boom ( ( feat . t-pain ) [ edited ] )</td>\n",
       "      <td>snoop dogg</td>\n",
       "      <td>doggumentary [ edited ]</td>\n",
       "      <td>rap &amp; hip-hop , west coast</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( c ) 2011 capitol records , llc</td>\n",
       "      <td>3:50</td>\n",
       "      <td>march 29 , 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>stars come out ( tim mason remix )</td>\n",
       "      <td>zedd</td>\n",
       "      <td>stars come out ( remixes ) - ep</td>\n",
       "      <td>dance , music , electronic , house</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>2012 dim mak inc .</td>\n",
       "      <td>5:49</td>\n",
       "      <td>20-may-14</td>\n",
       "      <td>stars come out ( dillon francis remix )</td>\n",
       "      <td>zedd</td>\n",
       "      <td>stars come out [ dillon francis remix ]</td>\n",
       "      <td>dance &amp; electronic</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>2012 dim mak inc .</td>\n",
       "      <td>4:08</td>\n",
       "      <td>may 20 , 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>485</td>\n",
       "      <td>0</td>\n",
       "      <td>jump ( feat . nelly furtado )</td>\n",
       "      <td>flo rida</td>\n",
       "      <td>r.o.o.t.s . ( deluxe version )</td>\n",
       "      <td>hip-hop/rap , music</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>‰ ãñ 2009 atlantic recording corporation for t...</td>\n",
       "      <td>3:28</td>\n",
       "      <td>30-mar-09</td>\n",
       "      <td>yayo [ feat . brisco , billy blue , ball greez...</td>\n",
       "      <td>flo rida</td>\n",
       "      <td>r.o.o.t.s . ( route of overcoming the struggle...</td>\n",
       "      <td>rap &amp; hip-hop</td>\n",
       "      <td>$ 1.29</td>\n",
       "      <td>( c ) 2012 motown records , a division of umg ...</td>\n",
       "      <td>7:53</td>\n",
       "      <td>march 30 , 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  label                                     left_Song_Name  \\\n",
       "0  448      0  baby when the light ( david guetta & fred rist...   \n",
       "1  287      1                                         outversion   \n",
       "2  534      0              peer pressure ( feat . traci nelson )   \n",
       "3  181      1                 stars come out ( tim mason remix )   \n",
       "4  485      0                      jump ( feat . nelly furtado )   \n",
       "\n",
       "  left_Artist_Name                                  left_Album_Name  \\\n",
       "0     david guetta  pop life ( extended version ) [ bonus version ]   \n",
       "1      mark ronson                                          version   \n",
       "2       snoop dogg                                     doggumentary   \n",
       "3             zedd                  stars come out ( remixes ) - ep   \n",
       "4         flo rida                   r.o.o.t.s . ( deluxe version )   \n",
       "\n",
       "                                          left_Genre left_Price  \\\n",
       "0  dance , music , rock , pop , house , electroni...     $ 1.29   \n",
       "1  pop , music , r & b / soul , soul , dance , ro...     $ 0.99   \n",
       "2  hip-hop/rap , music , rock , gangsta rap , wes...     $ 1.29   \n",
       "3                 dance , music , electronic , house     $ 1.29   \n",
       "4                                hip-hop/rap , music     $ 1.29   \n",
       "\n",
       "                                      left_CopyRight left_Time left_Released  \\\n",
       "0                              ‰ ãñ 2007 gum records      6:17     18-sep-07   \n",
       "1  2007 mark ronson under exclusive license to so...      1:50     10-jul-07   \n",
       "2  ‰ ãñ 2011 capitol records , llc . all rights r...      4:07     29-mar-11   \n",
       "3                                 2012 dim mak inc .      5:49     20-may-14   \n",
       "4  ‰ ãñ 2009 atlantic recording corporation for t...      3:28     30-mar-09   \n",
       "\n",
       "                                     right_Song_Name right_Artist_Name  \\\n",
       "0  revolver ( madonna vs. david guetta feat . lil...      david guetta   \n",
       "1                                         outversion       mark ronson   \n",
       "2              boom ( ( feat . t-pain ) [ edited ] )        snoop dogg   \n",
       "3            stars come out ( dillon francis remix )              zedd   \n",
       "4  yayo [ feat . brisco , billy blue , ball greez...          flo rida   \n",
       "\n",
       "                                    right_Album_Name  \\\n",
       "0                        one love ( deluxe version )   \n",
       "1                               version [ explicit ]   \n",
       "2                            doggumentary [ edited ]   \n",
       "3            stars come out [ dillon francis remix ]   \n",
       "4  r.o.o.t.s . ( route of overcoming the struggle...   \n",
       "\n",
       "                  right_Genre right_Price  \\\n",
       "0          dance & electronic      $ 1.29   \n",
       "1                         pop      $ 0.99   \n",
       "2  rap & hip-hop , west coast      $ 1.29   \n",
       "3          dance & electronic      $ 1.29   \n",
       "4               rap & hip-hop      $ 1.29   \n",
       "\n",
       "                                     right_CopyRight right_Time  \\\n",
       "0  ( c ) 2014 swedish house mafia holdings ltd ( ...       3:18   \n",
       "1                         ( c ) 2011 j'adore records       1:50   \n",
       "2                   ( c ) 2011 capitol records , llc       3:50   \n",
       "3                                 2012 dim mak inc .       4:08   \n",
       "4  ( c ) 2012 motown records , a division of umg ...       7:53   \n",
       "\n",
       "     right_Released  \n",
       "0  august 21 , 2009  \n",
       "1    july 10 , 2007  \n",
       "2   march 29 , 2011  \n",
       "3     may 20 , 2014  \n",
       "4   march 30 , 2009  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_table = train.get_raw_table()\n",
    "train_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model = dm.MatchingModel(attr_summarizer='hybrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MatchingModel(\n",
       "  (attr_summarizers): ModuleMap(\n",
       "    (Song_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Genre): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Price): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Time): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "    (Released): Hybrid(\n",
       "      (word_contextualizer): RNN(\n",
       "        (rnn_groups): ModuleList(\n",
       "          (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "        )\n",
       "        (dropouts): ModuleList(\n",
       "          (0): Dropout(p=0)\n",
       "        )\n",
       "        (bypass_networks): ModuleList(\n",
       "          (0): None\n",
       "        )\n",
       "        (input_dropout): NoMeta(\n",
       "          (module): Dropout(p=0)\n",
       "        )\n",
       "      )\n",
       "      (word_comparator): Attention(\n",
       "        (alignment_networks): ModuleList(\n",
       "          (0): AlignmentNetwork(\n",
       "            (transform): Transform(\n",
       "              (transforms): ModuleList(\n",
       "                (0): Linear(in_features=300, out_features=300, bias=True)\n",
       "                (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "              )\n",
       "              (bypass_networks): ModuleList(\n",
       "                (0): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "                (1): Bypass(\n",
       "                  (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (value_merge): Merge(\n",
       "        )\n",
       "        (comparison_merge): Merge(\n",
       "        )\n",
       "        (comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "            (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "            (1): Bypass(\n",
       "              (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "      (word_aggregator): AttentionWithRNN(\n",
       "        (rnn): RNN(\n",
       "          (rnn_groups): ModuleList(\n",
       "            (0): GRU(300, 150, batch_first=True, bidirectional=True)\n",
       "          )\n",
       "          (dropouts): ModuleList(\n",
       "            (0): Dropout(p=0)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "          (input_dropout): NoMeta(\n",
       "            (module): Dropout(p=0)\n",
       "          )\n",
       "        )\n",
       "        (rnn_pool): Pool(\n",
       "        )\n",
       "        (input_context_comparison_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=600, out_features=300, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): Bypass(\n",
       "              (highway_gate): Linear(in_features=600, out_features=300, bias=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (scoring_network): Transform(\n",
       "          (transforms): ModuleList(\n",
       "            (0): Linear(in_features=300, out_features=1, bias=True)\n",
       "          )\n",
       "          (bypass_networks): ModuleList(\n",
       "            (0): None\n",
       "          )\n",
       "        )\n",
       "        (input_dropout): Dropout(p=0)\n",
       "        (transform_dropout): Dropout(p=0)\n",
       "        (score_dropout): Dropout(p=0)\n",
       "        (softmax): Softmax()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_summarizer): Hybrid(\n",
       "  )\n",
       "  (attr_condensors): ModuleMap(\n",
       "    (Song_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Artist_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Album_Name): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Genre): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Price): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (CopyRight): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Time): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (Released): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=50, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=50, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (attr_comparators): ModuleMap(\n",
       "    (Song_Name): Merge(\n",
       "    )\n",
       "    (Artist_Name): Merge(\n",
       "    )\n",
       "    (Album_Name): Merge(\n",
       "    )\n",
       "    (Genre): Merge(\n",
       "    )\n",
       "    (Price): Merge(\n",
       "    )\n",
       "    (CopyRight): Merge(\n",
       "    )\n",
       "    (Time): Merge(\n",
       "    )\n",
       "    (Released): Merge(\n",
       "    )\n",
       "  )\n",
       "  (attr_comparator): Merge(\n",
       "  )\n",
       "  (attr_merge): Merge(\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        (1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): Bypass(\n",
       "          (highway_gate): Linear(in_features=1200, out_features=300, bias=True)\n",
       "        )\n",
       "        (1): Bypass(\n",
       "          (highway_gate): Linear(in_features=300, out_features=300, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (softmax_transform): Transform(\n",
       "      (transforms): ModuleList(\n",
       "        (0): Linear(in_features=300, out_features=2, bias=True)\n",
       "      )\n",
       "      (bypass_networks): ModuleList(\n",
       "        (0): None\n",
       "      )\n",
       "    )\n",
       "    (softmax): LogSoftmax()\n",
       "  )\n",
       "  (embed): ModuleMap(\n",
       "    (left_Song_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Album_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Genre): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Price): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_CopyRight): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Time): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (left_Released): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Song_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Artist_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Album_Name): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Genre): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Price): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_CopyRight): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Time): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "    (right_Released): NoMeta(\n",
       "      (module): Embedding(2227, 300)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run this cell if you want to load pre-trained model\n",
    "hybrid_model.load_state('models/hybrid_model.pth')\n",
    "hybrid_model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    best_save_path='models/hybrid_model.pth',\n",
    "    pos_neg_ratio=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_predictions = hybrid_model.run_prediction(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_pred = hybrid_model.run_prediction(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('sample_data/itunes-amazon/test.csv')\n",
    "test_df.loc[test_df['label'] == 0, 'left_Time'] = test_df['right_Time']\n",
    "test_df_negatives = test_df.loc[test_df['label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_negatives.to_csv('sample_data/itunes-amazon/altered_negatives.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_negatives = dm.data.process_unlabeled('sample_data/itunes-amazon/altered_negatives.csv',\n",
    "                                           hybrid_model,ignore_columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_model.run_prediction(altered_negatives,output_attributes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze intermediate layers\n",
    "In this step we want to evaluate the output of intermediate layers. For this purpose we use some utility functions from utility module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "we want to evaluate the differences between the output of the summarizers of positive samples and the output of the summarizers of altered positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ['Song_Name','Artist_Name','Album_Name','Genre','Price','CopyRight','Time','Released']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparators_datasets = dm.data.process(path='sample_data/itunes-amazon/',train='test.csv',\n",
    "                            validation='test_positives.csv',test='altered_positive_samples.csv',\n",
    "                                       cache='summarizer_cache.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmatcher.data import MatchingIterator\n",
    "batch_size = 32\n",
    "splits = MatchingIterator.splits(comparators_datasets,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_batches = []\n",
    "for batch in splits[1]:\n",
    "    positive_batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_positive_batches = []\n",
    "for batch in splits[2]:\n",
    "    altered_positive_batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_batches[0].id, altered_positive_batches[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizers = []\n",
    "#comparators useful only for debugging\n",
    "comparators = []\n",
    "for attr in attributes:\n",
    "    summarizers.append(hybrid_model.attr_summarizers[attr])\n",
    "    comparators.append(hybrid_model.attr_comparators[attr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hookF_summarizer = []\n",
    "for summ in summarizers:\n",
    "    hookF_summarizer.append(Hook(summ))\n",
    "hookF_comparator = []\n",
    "for comp in comparators:\n",
    "    hookF_comparator.append(Hook(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = hybrid_model.classifier\n",
    "hookF_classifier = []\n",
    "hookF_classifier.append(Hook(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_batch_layer_inputs,positives_batch_layer_outputs = return_layer_input_output(hookF_summarizer,\n",
    "                                                                                     positive_batches[0],hybrid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_batch_layer_inputs, altered_batch_layer_outputs = return_layer_input_output(hookF_summarizer,\n",
    "                                                                                    altered_positive_batches[0],hybrid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_summarizers_left_output = list(map(lambda x: x[0].data,positives_batch_layer_outputs))\n",
    "positives_summarizers_right_output = list(map(lambda x: x[1].data,positives_batch_layer_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altered_summarizers_left_output = list(map(lambda x: x[0].data,altered_batch_layer_outputs))\n",
    "altered_summarizers_right_output = list(map(lambda x:x[1].data,altered_batch_layer_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(summarizers_left_output,summarizers_right_output):\n",
    "    distance_mat = []\n",
    "    for i in range(len(summarizers_left_output)):\n",
    "        distances = []\n",
    "        for j in range(31):\n",
    "            l_out = summarizers_left_output[i][j].data\n",
    "            r_out = summarizers_right_output[i][j].data\n",
    "            dist = distance.euclidean(l_out,r_out)\n",
    "            distances.append(dist)\n",
    "        distance_mat.append(distances)\n",
    "    distance_mat = np.matrix(distance_mat)\n",
    "    return distance_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mat_positives = calculate_distance_matrix(positives_summarizers_left_output,positives_summarizers_right_output)\n",
    "distance_mat_positives = distance_mat_positives.reshape((31,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_positives_df = pd.DataFrame(data = distance_mat_positives,columns=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_positives_df.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_positives_df.to_csv('distances_positives_batch1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mat_altered = calculate_distance_matrix(altered_summarizers_left_output,altered_summarizers_right_output)\n",
    "distance_mat_altered = distance_mat_altered.reshape((31,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_altered_df = pd.DataFrame(data=distance_mat_altered,columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_altered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_altered_df.to_csv('distances_altered_batch1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_df = distances_positives_df.subtract(distances_altered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences_df.head(31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "We want to evaluate the distance between positive and negative example respect to the classifier input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distance_measures import calculate_closer_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_datasets = dm.data.process(path='sample_data/itunes-amazon/',train='negative_samples.csv',\n",
    "                            validation='positives_samples.csv',test='all_samples.csv',cache='pcache.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmatcher.data import MatchingIterator\n",
    "batch_size = 32\n",
    "splits = MatchingIterator.splits(classifier_datasets,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_batches = []\n",
    "for batch in splits[0]:\n",
    "    negative_batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_batches = [] \n",
    "for batch in splits[1]:\n",
    "    positive_batches.append(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = hybrid_model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hookF_classifier = []\n",
    "hookF_classifier.append(Hook(classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_classifier_inputs = []\n",
    "positive_classifier_outputs = []\n",
    "for batch in positive_batches:\n",
    "    classifier_input,classifier_output = return_layer_input_output(hookF_classifier,batch,hybrid_model)\n",
    "    positive_classifier_inputs.append(classifier_input)\n",
    "    positive_classifier_outputs.append(classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_classifier_inputs = []\n",
    "negative_classifier_outputs = []\n",
    "for batch in negative_batches:\n",
    "    classifier_input,classifier_output = return_layer_input_output(hookF_classifier,batch,hybrid_model)\n",
    "    negative_classifier_inputs.append(classifier_input)\n",
    "    negative_classifier_outputs.append(classifier_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_classifier_inputs = list(map(lambda x: x[0][0],positive_classifier_inputs))\n",
    "positive_classifier_outputs = list(map(lambda x: x[0][0],positive_classifier_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_classifier_inputs = list(map(lambda x: x[0][0],negative_classifier_inputs))\n",
    "negative_classifier_outputs = list(map(lambda x: x[0][0],negative_classifier_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proccessing vector\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d6ddbcef53dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_closer_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_classifier_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnegative_classifier_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/nvidia/workspace/dbgroup/vmartello/deepmatcher-experiments/distance_measures.py\u001b[0m in \u001b[0;36mcalculate_closer_vector\u001b[0;34m(pos_vector_list, neg_vector_list)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg_vector_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcurr_negative\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0mcurr_distance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distance_with_max_difference_dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mcurr_positive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcurr_negative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_distance\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mcurrent_min\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "calculate_closer_vector(positive_classifier_inputs,negative_classifier_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3\n",
    "Find attribute more sensible to variation inspecting classifier input and its gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distance_measures import find_smallest_variation_to_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 0 with attribute Song_Name\n",
      "Processing sample 0 with attribute Artist_Name\n",
      "Processing sample 0 with attribute Album_Name\n",
      "Processing sample 0 with attribute Genre\n",
      "Processing sample 0 with attribute Price\n",
      "Processing sample 0 with attribute CopyRight\n",
      "Processing sample 0 with attribute Time\n",
      "Processing sample 0 with attribute Released\n",
      "Processing sample 1 with attribute Song_Name\n",
      "Processing sample 1 with attribute Artist_Name\n",
      "Processing sample 1 with attribute Album_Name\n",
      "Processing sample 1 with attribute Genre\n",
      "Processing sample 1 with attribute Price\n",
      "Processing sample 1 with attribute CopyRight\n"
     ]
    }
   ],
   "source": [
    "attribute_lenght= len(attributes)\n",
    "variation_list = []\n",
    "current_sample = 0\n",
    "negative_classifier_inputs_subsample = negative_classifier_inputs[0:1]\n",
    "for batch in negative_classifier_inputs_subsample:\n",
    "    for index in range(len(batch)):\n",
    "        variation_norms = []\n",
    "        for j,attribute in enumerate(attributes):\n",
    "            print('Processing sample {} with attribute {}'.format(current_sample,attribute))\n",
    "            it,variation = find_smallest_variation_to_change(hybrid_model.classifier,batch,index,j,1)\n",
    "            variation_norms.append(torch.norm(variation))\n",
    "        variation_list.append(variation_norms)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sample 0 with attribute Song_Name\n",
      "Processing sample 0 with attribute Artist_Name\n",
      "Processing sample 0 with attribute Album_Name\n",
      "Processing sample 0 with attribute Genre\n",
      "Processing sample 0 with attribute Price\n",
      "Processing sample 0 with attribute CopyRight\n",
      "Processing sample 0 with attribute Time\n",
      "Processing sample 0 with attribute Released\n",
      "Processing sample 1 with attribute Song_Name\n",
      "Processing sample 1 with attribute Artist_Name\n",
      "Processing sample 1 with attribute Album_Name\n",
      "Processing sample 1 with attribute Genre\n",
      "Processing sample 1 with attribute Price\n",
      "Processing sample 1 with attribute CopyRight\n",
      "Processing sample 1 with attribute Time\n",
      "Processing sample 1 with attribute Released\n",
      "Processing sample 2 with attribute Song_Name\n",
      "Processing sample 2 with attribute Artist_Name\n",
      "Processing sample 2 with attribute Album_Name\n",
      "Processing sample 2 with attribute Genre\n",
      "Processing sample 2 with attribute Price\n",
      "Processing sample 2 with attribute CopyRight\n",
      "Processing sample 2 with attribute Time\n",
      "Processing sample 2 with attribute Released\n",
      "Processing sample 3 with attribute Song_Name\n",
      "Processing sample 3 with attribute Artist_Name\n",
      "Processing sample 3 with attribute Album_Name\n",
      "Processing sample 3 with attribute Genre\n",
      "Processing sample 3 with attribute Price\n",
      "Processing sample 3 with attribute CopyRight\n",
      "Processing sample 3 with attribute Time\n",
      "Processing sample 3 with attribute Released\n",
      "Processing sample 4 with attribute Song_Name\n",
      "Processing sample 4 with attribute Artist_Name\n",
      "Processing sample 4 with attribute Album_Name\n",
      "Processing sample 4 with attribute Genre\n",
      "Processing sample 4 with attribute Price\n",
      "Processing sample 4 with attribute CopyRight\n",
      "Processing sample 4 with attribute Time\n",
      "Processing sample 4 with attribute Released\n",
      "Processing sample 5 with attribute Song_Name\n",
      "Processing sample 5 with attribute Artist_Name\n",
      "Processing sample 5 with attribute Album_Name\n",
      "Processing sample 5 with attribute Genre\n",
      "Processing sample 5 with attribute Price\n",
      "Processing sample 5 with attribute CopyRight\n",
      "Processing sample 5 with attribute Time\n",
      "Processing sample 5 with attribute Released\n",
      "Processing sample 6 with attribute Song_Name\n",
      "Processing sample 6 with attribute Artist_Name\n",
      "Processing sample 6 with attribute Album_Name\n",
      "Processing sample 6 with attribute Genre\n",
      "Processing sample 6 with attribute Price\n",
      "Processing sample 6 with attribute CopyRight\n",
      "Processing sample 6 with attribute Time\n",
      "Processing sample 6 with attribute Released\n",
      "Processing sample 7 with attribute Song_Name\n",
      "Processing sample 7 with attribute Artist_Name\n",
      "Processing sample 7 with attribute Album_Name\n",
      "Processing sample 7 with attribute Genre\n",
      "Processing sample 7 with attribute Price\n",
      "Processing sample 7 with attribute CopyRight\n",
      "Processing sample 7 with attribute Time\n",
      "Processing sample 7 with attribute Released\n",
      "Processing sample 8 with attribute Song_Name\n",
      "Processing sample 8 with attribute Artist_Name\n",
      "Processing sample 8 with attribute Album_Name\n",
      "Processing sample 8 with attribute Genre\n",
      "Processing sample 8 with attribute Price\n",
      "Processing sample 8 with attribute CopyRight\n",
      "Processing sample 8 with attribute Time\n",
      "Processing sample 8 with attribute Released\n",
      "Processing sample 9 with attribute Song_Name\n",
      "Processing sample 9 with attribute Artist_Name\n",
      "Processing sample 9 with attribute Album_Name\n",
      "Processing sample 9 with attribute Genre\n",
      "Processing sample 9 with attribute Price\n",
      "Processing sample 9 with attribute CopyRight\n",
      "Processing sample 9 with attribute Time\n",
      "Processing sample 9 with attribute Released\n",
      "Processing sample 10 with attribute Song_Name\n",
      "Processing sample 10 with attribute Artist_Name\n",
      "Processing sample 10 with attribute Album_Name\n",
      "Processing sample 10 with attribute Genre\n",
      "Processing sample 10 with attribute Price\n",
      "Processing sample 10 with attribute CopyRight\n",
      "Processing sample 10 with attribute Time\n",
      "Processing sample 10 with attribute Released\n",
      "Processing sample 11 with attribute Song_Name\n",
      "Processing sample 11 with attribute Artist_Name\n",
      "Processing sample 11 with attribute Album_Name\n",
      "Processing sample 11 with attribute Genre\n",
      "Processing sample 11 with attribute Price\n",
      "Processing sample 11 with attribute CopyRight\n",
      "Processing sample 11 with attribute Time\n",
      "Processing sample 11 with attribute Released\n",
      "Processing sample 12 with attribute Song_Name\n",
      "Processing sample 12 with attribute Artist_Name\n",
      "Processing sample 12 with attribute Album_Name\n",
      "Processing sample 12 with attribute Genre\n",
      "Processing sample 12 with attribute Price\n",
      "Processing sample 12 with attribute CopyRight\n",
      "Processing sample 12 with attribute Time\n",
      "Processing sample 12 with attribute Released\n",
      "Processing sample 13 with attribute Song_Name\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-cebe1b9ff75b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processing sample {} with attribute {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvariation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_smallest_variation_to_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhybrid_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mvariation_norms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mvariation_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariation_norms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvidia/workspace/dbgroup/vmartello/deepmatcher-experiments/distance_measures.py\u001b[0m in \u001b[0;36mfind_smallest_variation_to_change\u001b[0;34m(layer, input_matrix, vector_index, attribute, class_to_reach)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mcurrent_match_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mgradient_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossentropy_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobabilities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mcurrent_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_match_score\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurrent_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mxi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvidia/workspace/dbgroup/vmartello/deepmatcher-experiments/distance_measures.py\u001b[0m in \u001b[0;36m_gradient\u001b[0;34m(output, vector_index, attribute, gradient_loss)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvector_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvidia/anaconda3/envs/testenv/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nvidia/anaconda3/envs/testenv/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attribute_lenght= len(attributes)\n",
    "variation_list = []\n",
    "current_sample = 0\n",
    "for batch in negative_classifier_inputs:\n",
    "    for index in range(len(batch)):\n",
    "        variation_norms = []\n",
    "        for j,attribute in enumerate(attributes):\n",
    "            print('Processing sample {} with attribute {}'.format(current_sample,attribute))\n",
    "            it,variation = find_smallest_variation_to_change(hybrid_model.classifier,batch,index,j,1)\n",
    "            variation_norms.append(torch.norm(variation))\n",
    "        variation_list.append(variation_norms)\n",
    "        current_sample+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distance_measures import get_probabilites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hybrid_model.classifier.forward(negative_classifier_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "it,variation =find_smallest_variation_to_change(hybrid_model.classifier,negative_classifier_inputs[1],31,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations_list = []\n",
    "for variationl in variation_list:\n",
    "    variations_list.append(list(map(lambda x:x.data[0],variationl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute variation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_gradients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(grad):\n",
    "    classifier_gradients.append(grad)\n",
    "    grad.data.zero_()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = negative_classifier_inputs[0].register_hook(get_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy_gradient(softmax_output,true_label):\n",
    "    return (softmax_output-true_label).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hybrid_model.classifier.forward(negative_classifier_inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.1730 -1.8395\n",
       "-0.1688 -1.8624\n",
       "-0.1395 -2.0387\n",
       "-0.1383 -2.0470\n",
       "-0.1736 -1.8365\n",
       "-0.1287 -2.1142\n",
       "-0.1421 -2.0216\n",
       "-0.1549 -1.9413\n",
       "-0.1677 -1.8685\n",
       "-0.1239 -2.1497\n",
       "-0.1505 -1.9684\n",
       "-0.1603 -1.9096\n",
       "-0.1540 -1.9470\n",
       "-0.1395 -2.0387\n",
       "-0.1615 -1.9031\n",
       "-0.1863 -1.7723\n",
       "-0.3900 -1.1302\n",
       "-0.1517 -1.9609\n",
       "-0.1508 -1.9665\n",
       "-0.1734 -1.8374\n",
       "-0.1538 -1.9481\n",
       "-0.5170 -0.9071\n",
       "-0.1599 -1.9122\n",
       "-0.2014 -1.7014\n",
       "-0.3147 -1.3094\n",
       "-0.1456 -1.9991\n",
       "-4.0174 -0.0182\n",
       "-0.1551 -1.9403\n",
       "-0.1454 -2.0000\n",
       "-0.1373 -2.0531\n",
       "-0.1543 -1.9451\n",
       "-0.1730 -1.8395\n",
       "[torch.FloatTensor of size 32x2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = Variable(torch.FloatTensor([1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilites = softmax(out[0],dim=0)\n",
    "gradients = crossentropy_gradient(probabilites,true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].backward(gradients,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "    0     0     0  ...      0     0     0\n",
       "[torch.FloatTensor of size 32x1200]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_gradients[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input = negative_classifier_inputs[0].clone()\n",
    "new_input[0].data= new_input[0].data.copy_(negative_classifier_inputs[0][0].data+classifier_gradients[0][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = hybrid_model.classifier.forward(new_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilites = softmax(out2[0],dim=0)\n",
    "gradients = crossentropy_gradient(probabilites,true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2[0].backward(gradients,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-03 *\n",
       " -0.8652\n",
       " -1.1622\n",
       "  0.6350\n",
       " -2.6656\n",
       " -0.8711\n",
       "  0.8956\n",
       " -3.5022\n",
       " -0.5527\n",
       "  0.6460\n",
       "  0.1270\n",
       " -0.2658\n",
       "  3.7434\n",
       " -5.0618\n",
       " -2.3652\n",
       " -1.3532\n",
       "  1.5847\n",
       "  2.7413\n",
       " -0.3356\n",
       " -0.0844\n",
       "  0.0341\n",
       "[torch.FloatTensor of size 20]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_gradients[1][0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_input2 = new_input.clone()\n",
    "new_input2[0].data= new_input[0].data.copy_(new_input[0].data+classifier_gradients[1][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3 = hybrid_model.classifier.forward(new_input2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilites = softmax(out3[0],dim=0)\n",
    "gradients = crossentropy_gradient(probabilites,true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.1424\n",
       " 0.1424\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "out3[0].backward(gradients,retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0628\n",
       " 0.7316\n",
       " 0.7216\n",
       "-0.0432\n",
       " 0.6927\n",
       "-0.0598\n",
       " 0.3550\n",
       "-0.1800\n",
       " 0.3194\n",
       "-0.0465\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input[0][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0625\n",
       " 0.7279\n",
       " 0.7266\n",
       "-0.0409\n",
       " 0.6941\n",
       "-0.0613\n",
       " 0.3523\n",
       "-0.1797\n",
       " 0.3194\n",
       "-0.0465\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input2[0][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.remove()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
